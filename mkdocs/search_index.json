{
    "docs": [
        {
            "location": "/", 
            "text": "ISV Integration Guide\n\n\nAs an Independent Software Vendor (ISV), you are likely to find more and more\nPivotal Cloud Foundry (PCF) users among your customers. Many of these will be\nasking you to integrate your software with PCF to enable use of your software\nwith the applications they are developing on PCF.\n\n\nPivotal is very supportive of these types of integrations and is committed to\nmaking this process as easy as possible. This site provides a \ntechnical\n\noverview on how to integrate your software with PCF. You are welcome to\nstart this process on your own, or \ncontact us\n\nto ask for our support and/or publish your integration in our\n\nmarketplace\n.\n\n\nIf you are new to this site, \nstart here\n.", 
            "title": "Home"
        }, 
        {
            "location": "/#isv-integration-guide", 
            "text": "As an Independent Software Vendor (ISV), you are likely to find more and more\nPivotal Cloud Foundry (PCF) users among your customers. Many of these will be\nasking you to integrate your software with PCF to enable use of your software\nwith the applications they are developing on PCF.  Pivotal is very supportive of these types of integrations and is committed to\nmaking this process as easy as possible. This site provides a  technical \noverview on how to integrate your software with PCF. You are welcome to\nstart this process on your own, or  contact us \nto ask for our support and/or publish your integration in our marketplace .  If you are new to this site,  start here .", 
            "title": "ISV Integration Guide"
        }, 
        {
            "location": "/getting-started/", 
            "text": "Getting Started\n\n\nAs an Independent Software Vendor (ISV), you are likely to find more and more\nPivotal Cloud Foundry (PCF) users among your customers. Many of these will be\nasking you to integrate your software with PCF to enable use of your software\nwith the applications they are developing on PCF.\n\n\nPivotal is very supportive of these types of integrations and is committed to\nmaking this process as easy as possible. This site provides a \ntechnical\n\noverview on how to integrate your software with PCF. You are welcome to\nstart this process on your own, or \ncontact us\n\nto ask for our support and/or publish your integration in our\n\nmarketplace\n.\n\n\nThere are a lot of things you will have to learn and do to complete an\nintegration with Cloud Foundry. This page attempts to lay out a typical\nprogression of an integration with PCF.\n\n\nStep 0. Understand the concepts\n\n\nThere are many ways to integrate products with Cloud Foundry.\nThe right one for each product depends on what the product does, and how\ncustomer applications consume it. To determine the best way to integrate your\nproduct, you'll need a good understanding of\n\nCloud Foundry concepts\n\nlike applications, containers, services, brokers, and buildpacks.\n\n\nStep 1. Design the integration\n\n\nWith sufficient understanding of both your product, and Cloud Foundry concepts,\nyou are in a position to decide what the integration looks like. Integration\npoints might include:\n\n\n\n\nService Brokers\n\n\nManaged Services\n\n\nBuildpacks\n\n\nEmbedded Agents\n\n\nNozzles\n\n\nOr any combination of the above\n\n\n\n\nIf you are not intimately familiar with Cloud Foundry, this is one of the\nareas where we can help. We like to do scoping meetings with you, where\nwe pair your understanding of your products, with our understanding of\nCloud Foundry, to map out the best possible integration path.\n\n\nStep 2. Learn how to build\n\n\nDepending on the selected type of integration, you will need to learn\nhow to build one or more of:\n\n\n\n\nService brokers\n\n\nManaged services\n\n\nDynamic services\n\n\nBuildpacks\n\n\nEmbedded agents\n\n\nNozzles\n\n\n\n\nSelf-learning is definitely possible. If you are interested in more\norganized learning, Pivotal provides many different classes and labs for\npartners and customers. \nContact us\n\nif your are interested in learning more about this.\n\n\nStep 3. Set up a test environment\n\n\nOnce you move into development, you will need access to a PCF environment.\nPartners who participate in our program have access to a number of shared\nenvironments that are operated and managed by Pivotal. If you are not (yet)\nin our program, need a dedicated environment, or want to be able to work\noffline, you can set up a PCF environment on:\n\n\n\n\nDeveloper desktop/laptop\n\n\nSupported public or private infrastructure (IaaS)\n\n\n\n\nYou will then also need to learn to operate and upgrade PCF by yourself:\n\n\n\n\nOperating a PCF environment\n\n\nUpgrading a PCF environment\n\n\n\n\nStep 4. Validate the design\n\n\nPivotal is a strong believer in lean and agile development and the notion\nof delivering a Minimal Viable Product (MVP) to our customers as quickly\nas possible. So we always look for \nstaged approaches\n to\nthe development of the integration, and only plan the upcoming stage in\ngreat detail.\n\n\nIn most cases, there is a very rapid way to do a proof-of-concept of the\nproposed integration. For instance, if you are building a service, you\ncan often emulate the availability of a brokered, managed, or dynamic\nservice by setting up a \nuser-provided service\n\nfor an existing instance of your service. That will let you validate\nthe integration design before you make a large development investment,\nand it will let real consumers weigh in on development priorities.\n\n\nA critical component to this step is the development of consuming\napplications. Those can be real customer applications, or test applications\nthat are deployed to PCF.\n\n\n\n\nDeveloping applications\n\n\nBinding services\n\n\n\n\nStep 5. Develop your tile\n\n\nOnce the design is established and validated, and the first \nstage\n\nhas been defined, you would start actual development of your tile.\n\n\n\n\nDevelop and test the individual components\n\n\nGenerate your tile\n\n\nTest the deploy and delete errands\n\n\nDeploy and test your tile\n\n\n\n\nStep 6. Publish your tile\n\n\n\n\nComplete the documentation\n\n\nWork with Pivotal to publish your tile\n\n\n\n\nStep 7. Maintain your tile\n\n\n\n\nSet up a Concourse Server\n\n\nSet up a Concourse Pipeline\n\n\n\n\nCreate a target PCF pool\n\n\n\n\n\n\nUpgrading tiles", 
            "title": "Getting Started"
        }, 
        {
            "location": "/getting-started/#getting-started", 
            "text": "As an Independent Software Vendor (ISV), you are likely to find more and more\nPivotal Cloud Foundry (PCF) users among your customers. Many of these will be\nasking you to integrate your software with PCF to enable use of your software\nwith the applications they are developing on PCF.  Pivotal is very supportive of these types of integrations and is committed to\nmaking this process as easy as possible. This site provides a  technical \noverview on how to integrate your software with PCF. You are welcome to\nstart this process on your own, or  contact us \nto ask for our support and/or publish your integration in our marketplace .  There are a lot of things you will have to learn and do to complete an\nintegration with Cloud Foundry. This page attempts to lay out a typical\nprogression of an integration with PCF.", 
            "title": "Getting Started"
        }, 
        {
            "location": "/getting-started/#step-0-understand-the-concepts", 
            "text": "There are many ways to integrate products with Cloud Foundry.\nThe right one for each product depends on what the product does, and how\ncustomer applications consume it. To determine the best way to integrate your\nproduct, you'll need a good understanding of Cloud Foundry concepts \nlike applications, containers, services, brokers, and buildpacks.", 
            "title": "Step 0. Understand the concepts"
        }, 
        {
            "location": "/getting-started/#step-1-design-the-integration", 
            "text": "With sufficient understanding of both your product, and Cloud Foundry concepts,\nyou are in a position to decide what the integration looks like. Integration\npoints might include:   Service Brokers  Managed Services  Buildpacks  Embedded Agents  Nozzles  Or any combination of the above   If you are not intimately familiar with Cloud Foundry, this is one of the\nareas where we can help. We like to do scoping meetings with you, where\nwe pair your understanding of your products, with our understanding of\nCloud Foundry, to map out the best possible integration path.", 
            "title": "Step 1. Design the integration"
        }, 
        {
            "location": "/getting-started/#step-2-learn-how-to-build", 
            "text": "Depending on the selected type of integration, you will need to learn\nhow to build one or more of:   Service brokers  Managed services  Dynamic services  Buildpacks  Embedded agents  Nozzles   Self-learning is definitely possible. If you are interested in more\norganized learning, Pivotal provides many different classes and labs for\npartners and customers.  Contact us \nif your are interested in learning more about this.", 
            "title": "Step 2. Learn how to build"
        }, 
        {
            "location": "/getting-started/#step-3-set-up-a-test-environment", 
            "text": "Once you move into development, you will need access to a PCF environment.\nPartners who participate in our program have access to a number of shared\nenvironments that are operated and managed by Pivotal. If you are not (yet)\nin our program, need a dedicated environment, or want to be able to work\noffline, you can set up a PCF environment on:   Developer desktop/laptop  Supported public or private infrastructure (IaaS)   You will then also need to learn to operate and upgrade PCF by yourself:   Operating a PCF environment  Upgrading a PCF environment", 
            "title": "Step 3. Set up a test environment"
        }, 
        {
            "location": "/getting-started/#step-4-validate-the-design", 
            "text": "Pivotal is a strong believer in lean and agile development and the notion\nof delivering a Minimal Viable Product (MVP) to our customers as quickly\nas possible. So we always look for  staged approaches  to\nthe development of the integration, and only plan the upcoming stage in\ngreat detail.  In most cases, there is a very rapid way to do a proof-of-concept of the\nproposed integration. For instance, if you are building a service, you\ncan often emulate the availability of a brokered, managed, or dynamic\nservice by setting up a  user-provided service \nfor an existing instance of your service. That will let you validate\nthe integration design before you make a large development investment,\nand it will let real consumers weigh in on development priorities.  A critical component to this step is the development of consuming\napplications. Those can be real customer applications, or test applications\nthat are deployed to PCF.   Developing applications  Binding services", 
            "title": "Step 4. Validate the design"
        }, 
        {
            "location": "/getting-started/#step-5-develop-your-tile", 
            "text": "Once the design is established and validated, and the first  stage \nhas been defined, you would start actual development of your tile.   Develop and test the individual components  Generate your tile  Test the deploy and delete errands  Deploy and test your tile", 
            "title": "Step 5. Develop your tile"
        }, 
        {
            "location": "/getting-started/#step-6-publish-your-tile", 
            "text": "Complete the documentation  Work with Pivotal to publish your tile", 
            "title": "Step 6. Publish your tile"
        }, 
        {
            "location": "/getting-started/#step-7-maintain-your-tile", 
            "text": "Set up a Concourse Server  Set up a Concourse Pipeline   Create a target PCF pool    Upgrading tiles", 
            "title": "Step 7. Maintain your tile"
        }, 
        {
            "location": "/cf-concepts/", 
            "text": "Cloud Foundry Concepts\n\n\nThere are many ways to integrate products with Cloud Foundry.\nThe right one for each product depends on what the product does, and how\ncustomer applications consume it. To determine the best way to integrate your\nproduct, you'll need a good understanding of Cloud Foundry concepts\nlike applications, containers, services, brokers, and buildpacks.\n\n\nThis page provides a collection of links to documentation for the most relevant\nconcepts. If you prefer to learn through guided training,\n\nask us\n about available training options.\n\n\nGeneral Overview\n\n\nFor general overview of Cloud Foundry, and the various ways to interact with it,\nuse the following links:\n\n\n\n\nCloud Foundry Subsystems\n\n\nCloud Foundry Command Line Interface\n\n\nPivotal Ops Manager\n\n\nPivotal Apps Manager\n\n\n\n\n \n\n\nApplications\n\n\nCloud Foundry is primarily a cloud native application platform. To understand how to\nintegrate your services with Cloud Foundry, it is important to understand how your\ncustomers are using the platform to develop, deploy, and operate their applications:\n\n\n\n\nDeploying Applications\n\n\nLogging and Monitoring\n\n\n\n\n \n\n\nServices\n\n\nMost value-add integrations are done by exposing your software to customer applications\nas services. To understand the service concepts, and what a service integration\nlooks like, read the following documentation:\n\n\n\n\nServices Overview\n\n\nCustom Services\n\n\n\n\n \n\n\nBuildpacks\n\n\nWhen application code is deployed to Cloud Foundry, it is processed by a language-specific\nbuildpack. Language buildpacks provide a convenient integration hook for any service that\nneeds to inspect or embellish application code. The meta-buildpack also provides a\nlanguage-agnostic way to inject your code into the application container image.\n\n\n\n\nApplication Staging Process\n\n\nLanguage Buildpacks\n\n\nMeta Buildpack\n\n\n\n\n \n\n\nEmbedded Agents\n\n\nSome integrations depend on the ability to inject code into the application container.\nWe refer to these injected components as \"container-embedded agents\".\n\nBuildpacks\n provide a mechanism to inject components into the application\ncontainer image, and the \n.profile.d\n directory provides a way to start agents before or\nalongside the customer application.\n\n\n\n\nAgent Injection with the meta-buildpack\n\n\nUsing .profile.d\n\n\n\n\n\n\nNozzles\n\n\nCloud Foundry's logging system, Loggregator,\nhas a feature called firehose. The firehose includes the combined stream of logs from all apps,\nplus metrics data from CF components, and is intended to be used by operators and administrators.\n\n\nA nozzle takes this data and forwards it to an external logging and/or metrics solution.\n\n\n\n\nLoggregator system", 
            "title": "Cloud Foundry Concepts"
        }, 
        {
            "location": "/cf-concepts/#cloud-foundry-concepts", 
            "text": "There are many ways to integrate products with Cloud Foundry.\nThe right one for each product depends on what the product does, and how\ncustomer applications consume it. To determine the best way to integrate your\nproduct, you'll need a good understanding of Cloud Foundry concepts\nlike applications, containers, services, brokers, and buildpacks.  This page provides a collection of links to documentation for the most relevant\nconcepts. If you prefer to learn through guided training, ask us  about available training options.", 
            "title": "Cloud Foundry Concepts"
        }, 
        {
            "location": "/cf-concepts/#general-overview", 
            "text": "For general overview of Cloud Foundry, and the various ways to interact with it,\nuse the following links:   Cloud Foundry Subsystems  Cloud Foundry Command Line Interface  Pivotal Ops Manager  Pivotal Apps Manager", 
            "title": "General Overview"
        }, 
        {
            "location": "/cf-concepts/#applications", 
            "text": "Cloud Foundry is primarily a cloud native application platform. To understand how to\nintegrate your services with Cloud Foundry, it is important to understand how your\ncustomers are using the platform to develop, deploy, and operate their applications:   Deploying Applications  Logging and Monitoring", 
            "title": "Applications"
        }, 
        {
            "location": "/cf-concepts/#services", 
            "text": "Most value-add integrations are done by exposing your software to customer applications\nas services. To understand the service concepts, and what a service integration\nlooks like, read the following documentation:   Services Overview  Custom Services", 
            "title": "Services"
        }, 
        {
            "location": "/cf-concepts/#buildpacks", 
            "text": "When application code is deployed to Cloud Foundry, it is processed by a language-specific\nbuildpack. Language buildpacks provide a convenient integration hook for any service that\nneeds to inspect or embellish application code. The meta-buildpack also provides a\nlanguage-agnostic way to inject your code into the application container image.   Application Staging Process  Language Buildpacks  Meta Buildpack", 
            "title": "Buildpacks"
        }, 
        {
            "location": "/cf-concepts/#embedded-agents", 
            "text": "Some integrations depend on the ability to inject code into the application container.\nWe refer to these injected components as \"container-embedded agents\". Buildpacks  provide a mechanism to inject components into the application\ncontainer image, and the  .profile.d  directory provides a way to start agents before or\nalongside the customer application.   Agent Injection with the meta-buildpack  Using .profile.d", 
            "title": "Embedded Agents"
        }, 
        {
            "location": "/cf-concepts/#nozzles", 
            "text": "Cloud Foundry's logging system, Loggregator,\nhas a feature called firehose. The firehose includes the combined stream of logs from all apps,\nplus metrics data from CF components, and is intended to be used by operators and administrators.  A nozzle takes this data and forwards it to an external logging and/or metrics solution.   Loggregator system", 
            "title": "Nozzles"
        }, 
        {
            "location": "/stages/", 
            "text": "Stages of Integration\n\n\nWhen integrating third-party software with Cloud Foundry, the integration\ntypically progresses through the same set of stages. We recommend this\nstaged approach because it enables early feedback on the value and the\ndesign of the integration, which helps make better decisions about future\nstages.\n\n\nFor service type integrations, the typical stages of integration are:\n\n\n\n\nUser-Provided Service\n\n\nBrokered Service\n\n\nManaged Service\n\n\nDynamic Service\n\n\n\n\nEach of these is described in more detail below. In general, user-experience\nand production-readiness improves as the integration\nprogresses through the stages. But none of the later stages is required.\nIntegration can stop and be declared complete (enough) after any of these.\n\n\nFor non-service integrations (such as applications or buildpacks), a similar\nstaged integration approach is often possible and desirable.\n\n\n \n\n\nStage 1. User-Provided Service\n\n\nEither your software is available as a SaaS-offering, or you already have a\nway to install software on-premise at a customer site. Or also likely, your\ncustomer already has your software, is now adopting PCF, and wants to be\nable to consume your software from applications deployed on PCF.\n\n\nIn most cases, customers can immediately start consuming your software from\ntheir PCF applications through the user-provided service mechanism available\nin Cloud Foundry. Tell them to create a user-provided service in their\napplication org and space using the command:\n\n\ncf create-user-provided-service \nmy-service-name\n -p \ncredentials\n'\n\n\n\n\nor \ncf cups\n for short. The \ncredentials\n argument should be a valid JSON\nstring that contains the URL and credentials necessary to connect to your\nexternally-deployed service.\n\n\nBy doing this, application developers can bind\nto your service and write all code necessary to access it through a Cloud\nFoundry service binding. It is a great way to determine what information\nneeds to be passed in the credential structure (useful in later integration\nstages), verify that the integration works, and develop a test application\nthat can continue to be used for later stages. And from the application\ndeveloper perspective, once this works, later stages will not require any\nfurther code changes. User-provided service bindings are fully compatible with\nbrokered service bindings.\n\n\n \n\n\nStage 2. Brokered Service\n\n\nThe first real improvement in user experience is achieved by creating a\n\nService Broker\n for your service. Service brokers allow\nyou to expose your services and plans in the \ncf marketplace\n, from which\nyour customers can then create their own service instances with a simple\n\ncf create-service\n. It eliminates the need for them to know the URLs and\ncredentials for your services - those are managed automatically by the\nbroker instead.\n\n\nBuilding a broker for a (still) externally deployed service is generally\na good way to be able to publish a first tile that adds real value for\ncustomers who have both your software and PCF.\n\n\n \n\n\nStage 3. Managed Service\n\n\nThe next step is to get your service to actually be deployed on PCF rather\nthan externally as you've traditionally done it. This is usually one of the\nmore involved stages as you will have to change your packaging to allow your\nservice components to be deployed by \nbosh\n onto the PCF\ninfrastructure.\n\n\nYou will have to learn about stemcells, bosh releases, and manifests. You\nwill also have to decide how your service maps to virtual machines and how\npersistent storage is managed.\n\n\nFor a Minimal Viable Product (MVP) version of a managed service, we typically\nrecommend that you aim for a single, shared service instance, and don't yet\nworry too much about High Availability of this instance. This stage is mostly\nabout getting the bosh packaging, deployment, and monitoring working\ncorrectly.\n\n\n \n\n\nStage 3b. High Availability\n\n\nOnce you have a managed service, you may decide to prioritize either\n\ndynamic provisioning\n of service instances, \nor\n making your\nsingle shared service instance more highly available.\n\n\nWhen properly configured, bosh monitors and restarts any failing processes\nand virtual machines that are part of your service deployment. But to\nfurther increase availability, you will have to think about spreading your\nresources across multiple availability zones or even regions, and replicating\nyour persistent storage across those as well.\n\n\n \n\n\nStage 4. Dynamic Service\n\n\nAll prior stages assume that you have a single instance of your software\ndeployed. That instance can be multi-tenant, and it can possibly be manually\nscaled to accomodate many concurrent applications. But for real production\ndeployments, most of your customers will want dedicated instances of your\nservice for each application.\n\n\nWith bosh 2.0, Cloud Foundry has the ability to dynamically provision a\ncompletely new bosh deployment of your software for each service instance.\nThis is known as \"dynamic\" or \"on-demand\" service provisioning.\n\n\nStage 4b. High Availability\n\n\nIf you hadn't already in Stage 3b, the final step would be to consider how\neach of your dynamically provisioned service instances can be made more\nhighly available.", 
            "title": "Stages of Integration"
        }, 
        {
            "location": "/stages/#stages-of-integration", 
            "text": "When integrating third-party software with Cloud Foundry, the integration\ntypically progresses through the same set of stages. We recommend this\nstaged approach because it enables early feedback on the value and the\ndesign of the integration, which helps make better decisions about future\nstages.  For service type integrations, the typical stages of integration are:   User-Provided Service  Brokered Service  Managed Service  Dynamic Service   Each of these is described in more detail below. In general, user-experience\nand production-readiness improves as the integration\nprogresses through the stages. But none of the later stages is required.\nIntegration can stop and be declared complete (enough) after any of these.  For non-service integrations (such as applications or buildpacks), a similar\nstaged integration approach is often possible and desirable.", 
            "title": "Stages of Integration"
        }, 
        {
            "location": "/stages/#stage-1-user-provided-service", 
            "text": "Either your software is available as a SaaS-offering, or you already have a\nway to install software on-premise at a customer site. Or also likely, your\ncustomer already has your software, is now adopting PCF, and wants to be\nable to consume your software from applications deployed on PCF.  In most cases, customers can immediately start consuming your software from\ntheir PCF applications through the user-provided service mechanism available\nin Cloud Foundry. Tell them to create a user-provided service in their\napplication org and space using the command:  cf create-user-provided-service  my-service-name  -p  credentials '  or  cf cups  for short. The  credentials  argument should be a valid JSON\nstring that contains the URL and credentials necessary to connect to your\nexternally-deployed service.  By doing this, application developers can bind\nto your service and write all code necessary to access it through a Cloud\nFoundry service binding. It is a great way to determine what information\nneeds to be passed in the credential structure (useful in later integration\nstages), verify that the integration works, and develop a test application\nthat can continue to be used for later stages. And from the application\ndeveloper perspective, once this works, later stages will not require any\nfurther code changes. User-provided service bindings are fully compatible with\nbrokered service bindings.", 
            "title": "Stage 1. User-Provided Service"
        }, 
        {
            "location": "/stages/#stage-2-brokered-service", 
            "text": "The first real improvement in user experience is achieved by creating a Service Broker  for your service. Service brokers allow\nyou to expose your services and plans in the  cf marketplace , from which\nyour customers can then create their own service instances with a simple cf create-service . It eliminates the need for them to know the URLs and\ncredentials for your services - those are managed automatically by the\nbroker instead.  Building a broker for a (still) externally deployed service is generally\na good way to be able to publish a first tile that adds real value for\ncustomers who have both your software and PCF.", 
            "title": "Stage 2. Brokered Service"
        }, 
        {
            "location": "/stages/#stage-3-managed-service", 
            "text": "The next step is to get your service to actually be deployed on PCF rather\nthan externally as you've traditionally done it. This is usually one of the\nmore involved stages as you will have to change your packaging to allow your\nservice components to be deployed by  bosh  onto the PCF\ninfrastructure.  You will have to learn about stemcells, bosh releases, and manifests. You\nwill also have to decide how your service maps to virtual machines and how\npersistent storage is managed.  For a Minimal Viable Product (MVP) version of a managed service, we typically\nrecommend that you aim for a single, shared service instance, and don't yet\nworry too much about High Availability of this instance. This stage is mostly\nabout getting the bosh packaging, deployment, and monitoring working\ncorrectly.", 
            "title": "Stage 3. Managed Service"
        }, 
        {
            "location": "/stages/#stage-3b-high-availability", 
            "text": "Once you have a managed service, you may decide to prioritize either dynamic provisioning  of service instances,  or  making your\nsingle shared service instance more highly available.  When properly configured, bosh monitors and restarts any failing processes\nand virtual machines that are part of your service deployment. But to\nfurther increase availability, you will have to think about spreading your\nresources across multiple availability zones or even regions, and replicating\nyour persistent storage across those as well.", 
            "title": "Stage 3b. High Availability"
        }, 
        {
            "location": "/stages/#stage-4-dynamic-service", 
            "text": "All prior stages assume that you have a single instance of your software\ndeployed. That instance can be multi-tenant, and it can possibly be manually\nscaled to accomodate many concurrent applications. But for real production\ndeployments, most of your customers will want dedicated instances of your\nservice for each application.  With bosh 2.0, Cloud Foundry has the ability to dynamically provision a\ncompletely new bosh deployment of your software for each service instance.\nThis is known as \"dynamic\" or \"on-demand\" service provisioning.", 
            "title": "Stage 4. Dynamic Service"
        }, 
        {
            "location": "/stages/#stage-4b-high-availability", 
            "text": "If you hadn't already in Stage 3b, the final step would be to consider how\neach of your dynamically provisioned service instances can be made more\nhighly available.", 
            "title": "Stage 4b. High Availability"
        }, 
        {
            "location": "/development/", 
            "text": "Tile Development Process\n\n\nThe ultimate deliverable of a PCF integration is almost always a \"tile\", a\nPivotal Cloud Foundry installation package that is delivered through our\n\nmarketplace\n and installed through Pivotal's\nOps Manager. But when developing an integration, it is advisable to start\nwith smaller components of that tile, as it allows you to iterate on those\ncomponents much faster. Our recommendation is to approach development in\nphases:\n\n\n\n\nDevelop and test each of the components to be deployed individually\n\n\nDescribe your tile and generate the tile artifacts\n\n\nTest the generated artifacts individually\n\n\nTest deployment of the complete tile\n\n\nImplement Continuous Integration (CI) for the complete tile\n\n\n\n\nIf you follow this approach, you may not have a dependency on a complete\nPCF installation until step 4, and your iterations on the components will\nbe much faster than if you attempt to test them through actual deployment\nto PCF.\n\n\nEach of the development phases is described in more detail below.\n\n\n \n\n\nDevelop the Tile Components\n\n\nTiles are a packaging format to deliver ISV software to PCF customers. Most\ntiles contain one or more of the following types of components:\n\n\n\n\nService Brokers\n\n\nManaged Services\n\n\nBuildpacks\n\n\nApplications\n\n\n\n\nIt is much more efficient to develop and test these components individually\nthan it is to test them through tile deployment. So before you start generating\nand deploying tiles, \nalways\n make sure that the components you are deploying\nalready work, individually and in whatever combination you intend to deploy\nthem as a tile.\n\n\nIn most cases, you will not need a full PCF installation to complete these\nearly phases. You can set up a\n\nlight-weight PCF development environment\n on your laptop\nor desktop, possibly including bosh-lite if your are developing managed\nservices.\n\n\n \n\n\nDescribe and Generate your Tile\n\n\nAfter\n your components are in working order, download and install the\n\nTile Generator\n and follow the instructions to describe\nand generate your actual tile. This is where you list all the components that\nare to be included, add an icon and a description, and have the option to add\nforms for values that are to be configured by the PCF operator at installation\ntime.\n\n\n \n\n\nTest the Deploy and Delete Errands\n\n\nThis is the first step for which you will need a\n\ncomplete PCF deployment\n. But before you deploy your complete\ntile to Ops Manager, you can manually deploy your individual\n\ncomponents\n and test the errands created by the Tile Generator\nusing the \npcf utility\n. Doing this is significantly\nfaster than testing the errands through Ops Manager and bosh, as bosh will\nrun each errand in a newly created virtual machine.\n\n\n \n\n\nDeploy and Test your Tile\n\n\nAfter you have verified that all individual \ncomponents\n and\n\nerrands\n work, you are ready to deploy your tile as your customers\nwould, by uploading it to Ops Manager, installing and configuring the tile,\nand having Ops Manager apply your changes to the PCF deployment.\n\n\nThe only things you should be testing in this phaase are the things that\ncould not be tested in earlier ones:\n\n\n\n\nThe appearance of the tile forms in Ops Manager\n\n\nThe upgrade/migration steps from one version of a tile to another (if applicable)\n\n\n\n\nEverything else should be working exactly as it did in prior steps.", 
            "title": "Development Process"
        }, 
        {
            "location": "/development/#tile-development-process", 
            "text": "The ultimate deliverable of a PCF integration is almost always a \"tile\", a\nPivotal Cloud Foundry installation package that is delivered through our marketplace  and installed through Pivotal's\nOps Manager. But when developing an integration, it is advisable to start\nwith smaller components of that tile, as it allows you to iterate on those\ncomponents much faster. Our recommendation is to approach development in\nphases:   Develop and test each of the components to be deployed individually  Describe your tile and generate the tile artifacts  Test the generated artifacts individually  Test deployment of the complete tile  Implement Continuous Integration (CI) for the complete tile   If you follow this approach, you may not have a dependency on a complete\nPCF installation until step 4, and your iterations on the components will\nbe much faster than if you attempt to test them through actual deployment\nto PCF.  Each of the development phases is described in more detail below.", 
            "title": "Tile Development Process"
        }, 
        {
            "location": "/development/#develop-the-tile-components", 
            "text": "Tiles are a packaging format to deliver ISV software to PCF customers. Most\ntiles contain one or more of the following types of components:   Service Brokers  Managed Services  Buildpacks  Applications   It is much more efficient to develop and test these components individually\nthan it is to test them through tile deployment. So before you start generating\nand deploying tiles,  always  make sure that the components you are deploying\nalready work, individually and in whatever combination you intend to deploy\nthem as a tile.  In most cases, you will not need a full PCF installation to complete these\nearly phases. You can set up a light-weight PCF development environment  on your laptop\nor desktop, possibly including bosh-lite if your are developing managed\nservices.", 
            "title": "Develop the Tile Components"
        }, 
        {
            "location": "/development/#describe-and-generate-your-tile", 
            "text": "After  your components are in working order, download and install the Tile Generator  and follow the instructions to describe\nand generate your actual tile. This is where you list all the components that\nare to be included, add an icon and a description, and have the option to add\nforms for values that are to be configured by the PCF operator at installation\ntime.", 
            "title": "Describe and Generate your Tile"
        }, 
        {
            "location": "/development/#test-the-deploy-and-delete-errands", 
            "text": "This is the first step for which you will need a complete PCF deployment . But before you deploy your complete\ntile to Ops Manager, you can manually deploy your individual components  and test the errands created by the Tile Generator\nusing the  pcf utility . Doing this is significantly\nfaster than testing the errands through Ops Manager and bosh, as bosh will\nrun each errand in a newly created virtual machine.", 
            "title": "Test the Deploy and Delete Errands"
        }, 
        {
            "location": "/development/#deploy-and-test-your-tile", 
            "text": "After you have verified that all individual  components  and errands  work, you are ready to deploy your tile as your customers\nwould, by uploading it to Ops Manager, installing and configuring the tile,\nand having Ops Manager apply your changes to the PCF deployment.  The only things you should be testing in this phaase are the things that\ncould not be tested in earlier ones:   The appearance of the tile forms in Ops Manager  The upgrade/migration steps from one version of a tile to another (if applicable)   Everything else should be working exactly as it did in prior steps.", 
            "title": "Deploy and Test your Tile"
        }, 
        {
            "location": "/tile-documentation/", 
            "text": "Tile Documentation Template\n\n\nThis document offers a template for preparing documentation for partner services that appear on PivNet. The documentation will be posted on the front page of \nhttp://docs.pivotal.io\n\nunder \u201cPartner Services for Pivotal Cloud Foundry.\u201d\n\n\nWhile the specifics will vary depending on the product, we have provided a basic blueprint below. At minimum, documentation should include #1 (Overview) and #2 (Installing/Configuring).\n\n\nFor a good example of a partner service doc, see the\n\nJFrog Artifactory docs\n.\n\n\nIf you have questions or want to collaborate on drafting the documentation, feel free to hop on our Slack channel #pcf-docs. We\u2019re always happy to help!\n\n\nOverview\n\n\nGeneral overview of Partner Product. What does it do? What are its features?\n\n\nKey Features\n\n\n\n\nFeature one\n\n\nFeature two\n\n\nFeature three\n\n\n\n\nPartner Service Broker\n\n\nA Service Broker allows Cloud Foundry applications to bind to services and consume the services easily from App Manager UI or command line. The Partner Service Broker will enable you to use one or more Partner accounts and is deployed as a Java Application on Cloud Foundry. The Broker exposes the Partner service on the Cloud Foundry Marketplace and allows users to directly create a service instance and bind it to their applications either from the Pivotal Apps Manager Console or from the command line. \n\n\nThe PCF (Pivotal Cloud Foundry) Tile for Partner installs the Partner Service Broker as an application and registers it as a Service Broker on Cloud Foundry and exposes its service plans on the Marketplace.  This makes the installation and subsequent use of Partner on your Cloud Foundry applications simple and easy. \n\n\nIf trial license available =\n Customers interested in using Partner can obtain a 60 day free trial license from edit link here.\n\n\nProduct Snapshot\n\n\nCurrent Partner Tile for Pivotal Cloud Foundry Details:\n\n\n\n\nVersion:\n\n\nRelease Date: \n\n\nSoftware components versions: Partner product version\n\n\nCompatible Ops Manager Version(s): 1.5.x, 1.6.x\n\n\nCompatible Elastic Runtime Version(s): 1.4.x, 1.5.x, 1.6.x\n\n\n\n\nRequirements\n\n\n(or Prerequisites, Packaging Dependencies for Offline Buildpacks, etc.)\n\n\nProvide any general or specific requirements here. A general requirement might be something like, \u201cAn AppDynamics account.\u201d A specific requirement might be something like, \u201cPackaging Dependencies for Offline Buildpacks.\u201d\n\n\nLimitations\n\n\nAny known limitations.\n\n\nFeedback\n\n\nPlease provide any bugs, feature requests, or questions to the Pivotal Cloud Foundry Feedback list.\n\n\nInstalling / Configuring the Tile\n\n\nThis topic provides instructions for how to install and configure the tile. Typically this includes procedures for how to download the tile from PivNet, install it on Ops Manager, configure the tile, and do any required third-party configuration. Screenshots should be provided where necessary. Consult the following format:\n\n\nInstall via Pivotal Ops Manager\n\n\n\n\nDownload the product file from Pivotal Network (edit link).\n\n\nUpload the product file to your Ops Manager installation.\n\n\nClick Add next to the uploaded product description in the Ops Manager Available Products view to add this product to your staging area.\n\n\nClick the newly added tile to review any configurable options.\n\n\nClick Apply Changes to install the service.\n\n\n\n\nUpgrading to the Latest Version\n\n\nIf there are any specific instructions for upgrading the tile, you can include those here. If the procedures are complicated, create a new Upgrading topic.\n\n\nConfiguring the Partner Tile\n\n\n(add snapshots for each step when possible or add details as required)\n\n\n\n\nLogin into Pivotal Ops Manager \n\n\nClick on \u201cImport a Product\u201d and import the Partner Tile\n\n\nSelect the Partner option\n\n\nClick Add on the Partner Tile\n\n\nSelect the Partner Tile\n\n\nConfigure the Partner Tile\n\n\nApply your changes.\n\n\n\n\nOn completion of Partner Tile install, check Services Marketplace in Apps Manager\n\n\n\n\nView Partner Service Plans\n\n\nBind the Partner Service to an Application\n\n\nCheck the service or dashboard for the partner for more data\u2026\n\n\n\n\nOther Configurations / Third-Party Configurations\n\n\nProvide information for specific configurations like configuring for HTTP proxy, or doing any necessary configurations on a third-party service portal.\n\n\nUsing the Tile\n\n\nThis topic provides instructions for how to use the tile. Typically this includes \nprocedures for how to perform the different functions offered by the service. Screenshots should be provided where necessary. You can also include information about Architecture here if necessary.\n\n\nTroubleshooting\n\n\nThis topic provides troubleshooting information for known errors, following the Symptom/Explanation format used here:\n\nhttp://docs.pivotal.io/p-identity/okta/troubleshooting.html\n\n\nRelease Notes\n\n\nInclude the release notes as the final topic, following the format below. For reference, see the\n\nJFrog Artifactory Release Notes\n.\n\n\n\n\nVersion number:\n\n\nRelease date:\n\n\n\n\nFeatures included in this release:\n\n\n\n\nFirst feature.\n\n\nSecond feature.\n\n\nThird feature.", 
            "title": "Documentation"
        }, 
        {
            "location": "/tile-documentation/#tile-documentation-template", 
            "text": "This document offers a template for preparing documentation for partner services that appear on PivNet. The documentation will be posted on the front page of  http://docs.pivotal.io \nunder \u201cPartner Services for Pivotal Cloud Foundry.\u201d  While the specifics will vary depending on the product, we have provided a basic blueprint below. At minimum, documentation should include #1 (Overview) and #2 (Installing/Configuring).  For a good example of a partner service doc, see the JFrog Artifactory docs .  If you have questions or want to collaborate on drafting the documentation, feel free to hop on our Slack channel #pcf-docs. We\u2019re always happy to help!", 
            "title": "Tile Documentation Template"
        }, 
        {
            "location": "/tile-documentation/#overview", 
            "text": "General overview of Partner Product. What does it do? What are its features?  Key Features   Feature one  Feature two  Feature three", 
            "title": "Overview"
        }, 
        {
            "location": "/tile-documentation/#partner-service-broker", 
            "text": "A Service Broker allows Cloud Foundry applications to bind to services and consume the services easily from App Manager UI or command line. The Partner Service Broker will enable you to use one or more Partner accounts and is deployed as a Java Application on Cloud Foundry. The Broker exposes the Partner service on the Cloud Foundry Marketplace and allows users to directly create a service instance and bind it to their applications either from the Pivotal Apps Manager Console or from the command line.   The PCF (Pivotal Cloud Foundry) Tile for Partner installs the Partner Service Broker as an application and registers it as a Service Broker on Cloud Foundry and exposes its service plans on the Marketplace.  This makes the installation and subsequent use of Partner on your Cloud Foundry applications simple and easy.   If trial license available =  Customers interested in using Partner can obtain a 60 day free trial license from edit link here.", 
            "title": "Partner Service Broker"
        }, 
        {
            "location": "/tile-documentation/#product-snapshot", 
            "text": "Current Partner Tile for Pivotal Cloud Foundry Details:   Version:  Release Date:   Software components versions: Partner product version  Compatible Ops Manager Version(s): 1.5.x, 1.6.x  Compatible Elastic Runtime Version(s): 1.4.x, 1.5.x, 1.6.x", 
            "title": "Product Snapshot"
        }, 
        {
            "location": "/tile-documentation/#requirements", 
            "text": "(or Prerequisites, Packaging Dependencies for Offline Buildpacks, etc.)  Provide any general or specific requirements here. A general requirement might be something like, \u201cAn AppDynamics account.\u201d A specific requirement might be something like, \u201cPackaging Dependencies for Offline Buildpacks.\u201d", 
            "title": "Requirements"
        }, 
        {
            "location": "/tile-documentation/#limitations", 
            "text": "Any known limitations.", 
            "title": "Limitations"
        }, 
        {
            "location": "/tile-documentation/#feedback", 
            "text": "Please provide any bugs, feature requests, or questions to the Pivotal Cloud Foundry Feedback list.", 
            "title": "Feedback"
        }, 
        {
            "location": "/tile-documentation/#installing-configuring-the-tile", 
            "text": "This topic provides instructions for how to install and configure the tile. Typically this includes procedures for how to download the tile from PivNet, install it on Ops Manager, configure the tile, and do any required third-party configuration. Screenshots should be provided where necessary. Consult the following format:", 
            "title": "Installing / Configuring the Tile"
        }, 
        {
            "location": "/tile-documentation/#install-via-pivotal-ops-manager", 
            "text": "Download the product file from Pivotal Network (edit link).  Upload the product file to your Ops Manager installation.  Click Add next to the uploaded product description in the Ops Manager Available Products view to add this product to your staging area.  Click the newly added tile to review any configurable options.  Click Apply Changes to install the service.", 
            "title": "Install via Pivotal Ops Manager"
        }, 
        {
            "location": "/tile-documentation/#upgrading-to-the-latest-version", 
            "text": "If there are any specific instructions for upgrading the tile, you can include those here. If the procedures are complicated, create a new Upgrading topic.", 
            "title": "Upgrading to the Latest Version"
        }, 
        {
            "location": "/tile-documentation/#configuring-the-partner-tile", 
            "text": "(add snapshots for each step when possible or add details as required)   Login into Pivotal Ops Manager   Click on \u201cImport a Product\u201d and import the Partner Tile  Select the Partner option  Click Add on the Partner Tile  Select the Partner Tile  Configure the Partner Tile  Apply your changes.   On completion of Partner Tile install, check Services Marketplace in Apps Manager   View Partner Service Plans  Bind the Partner Service to an Application  Check the service or dashboard for the partner for more data\u2026", 
            "title": "Configuring the Partner Tile"
        }, 
        {
            "location": "/tile-documentation/#other-configurations-third-party-configurations", 
            "text": "Provide information for specific configurations like configuring for HTTP proxy, or doing any necessary configurations on a third-party service portal.", 
            "title": "Other Configurations / Third-Party Configurations"
        }, 
        {
            "location": "/tile-documentation/#using-the-tile", 
            "text": "This topic provides instructions for how to use the tile. Typically this includes \nprocedures for how to perform the different functions offered by the service. Screenshots should be provided where necessary. You can also include information about Architecture here if necessary.", 
            "title": "Using the Tile"
        }, 
        {
            "location": "/tile-documentation/#troubleshooting", 
            "text": "This topic provides troubleshooting information for known errors, following the Symptom/Explanation format used here: http://docs.pivotal.io/p-identity/okta/troubleshooting.html", 
            "title": "Troubleshooting"
        }, 
        {
            "location": "/tile-documentation/#release-notes", 
            "text": "Include the release notes as the final topic, following the format below. For reference, see the JFrog Artifactory Release Notes .   Version number:  Release date:   Features included in this release:   First feature.  Second feature.  Third feature.", 
            "title": "Release Notes"
        }, 
        {
            "location": "/concourse/", 
            "text": "Concourse Continuous Integration\n\n\nCloud Foundry is a fast moving platform as we are constantly extending and\nenhancing it. When you integrate your software with Cloud Foundry, it is\nimportant to make sure that your integration continues to work with every\nnew release of the platform. A great way to ensure that is to set up a CI\npipeline for your tile against a PCF deployment that is constantly updated\nwith the latest Alpha release of the platform.\n\n\nOur tool of choice for setting up CI is \nconcourse\n.\nWhile you are of course free to use whetever system you are familiar with,\nour tools and documentation are built to make concourse CI as easy as\npossible.\n\n\n \n\n\nSetting up a Concourse Server\n\n\nYou will need a concourse server to host your pipeline. If you partner with\nus, we have servers that can host your pipeline, and S3 storage that can be\nused to transfer artifacts to and from your servers. If you choose to set\nup your own, instructions can be found here:\n\n\n\n\nSetting up concourse\n\n\n\n\n \n\n\nCreating a Concourse Pipeline for your Tile\n\n\nA typical CI pipeline for a tile consists of the following jobs:\n\n\n\n\nBuild the tile\n\n\nDeploy it to PCF\n\n\nRun a set of deployment tests to verify that it deployed and works correctly\n\n\nRemove it from PCF\n\n\n\n\nYou describe this pipeline in a pipeline.yml file that is then uploaded to the\nconcourse server. \nTile Generator\n contains a sample\npipeline that you can clone for your own tile. \n\n\nWe have provided a \ndocker image\n to help you \nautomate your tile creation tasks via concourse. To make use of this image, you will want to do the following:\n\n\n\n\nDeclare a concourse resource for the tile source in your pipeline.yml file:\n\n\n\n\nyml\n  - name: tile-source\n    type: git\n    source:\n      branch: master\n      uri: https://github.com/your-tile-project-repo\n\n1. Declare a resource to store the artifacts of your build process (for example, an aws s3 bucket) in your pipeline.yml file:\n\n\nyml\n  - name: tile-build\n    type: s3\n    source:\n      access_key_id: your-aws-key-id-don't-check-this-in!\n      bucket: your-aws-bucket-name\n      regexp: .*-(?P\nversion\n.*)\\.jar\n      secret_access_key: your-aws-access-key-don't-check-this-in!\n\n1. Declare a resource to store your tile in your pipeline.yml file:\n\n\nyml\n  - name: tile\n    type: s3\n    source:\n      access_key_id: your-aws-key-id-don't-check-this-in!\n      bucket: your-aws-bucket-name\n      regexp: .*-(?P\nversion\n.*)\\.pivotal\n      secret_access_key: your-aws-access-key-don't-check-this-in!\n\n1. Declare a resource to store a tile-history.yml file. This file is needed by the tile-generator process:\n\n\nyml\n  - name: tile-history\n    type: s3\n    source:\n      access_key_id: your-aws-key-id-don't-check-this-in!\n      bucket: your-aws-bucket-name\n      regexp: tile-history-(?P\nversion\n.*)\\.yml\n      secret_access_key: your-aws-access-key-don't-check-this-in!\n\n1. (Optional) consider managing the versioning of your project via \nsemver\n. If you decide to do this, add something like the following to your pipeline.yml file:\n\n\nyml\n  - name: version\n    type: semver\n    source:\n      bucket: your-aws-bucket-name\n      key: current-version\n      access_key_id: your-aws-key-id-don't-check-this-in!\n      secret_access_key: your-aws-access-key-don't-check-this-in!\n      initial_version: 1.0.0\n\n1. add a job such as the following, to your pipeline:\n\n\nyml\n  - name: build-tile\n    serial_groups: [version]\n    plan:\n    - aggregate:\n      - get: tile-source\n      - get: tile-build\n      - get: version\n      - get: tile-history\n    - task: build-tile\n      file: tile-source/ci/build-tile/task.yml\n    - put: tile-history\n      params: {file: tile-history-new/*.yml}\n    - put: tile\n      params: {file: broker-tile/*.pivotal}\n\n1. define the tile build task via a task.yml file (per the above job configuration, this file would be added to the ci/build-tile directory in your source repository):\n\n\n```yml\n  platform: linux\n\n\nimage: docker:///cfplatformeng/tile-generator\n\n\ninputs:\n  - name: tile-source\n  - name: tile-build\n  - name: version\n  - name: tile-history\n\n\noutputs:\n  - name: tile\n  - name: tile-history-new\n\n\nrun:\n    path: tile-repo/ci/build-tile/task.sh\n```\n1. create a task.sh script to build the tile (per the above job configuration, this file would be added to the ci/build-tile directory in your source repository):\n\n\n```sh\n  #!/bin/sh -ex\n\n\ncd tile-repo\n\n\ncp ../../tile-build/* the-place-in-tile.yml-where-the-build-goes\n\n\nver=\nmore ../version/number\n\n  tile build ${ver}\n\n\nfile=\nls product/*.pivotal\n\n  filename=$(basename \"${file}\")\n  filename=\"${filename%-*}\"\n\n\ncp ${file} ../tile/${filename}-${ver}.pivotal\n  cp tile-history.yml ../tile-history-new/tile-history-${ver}.yml\n  ``` \n1. string this job together with the other jobs in your pipeline (probably after a successful tile-build). The job will then build your tile and place it in your s3 bucket along with an updated tile-history file.\n\n\n \n\n\nSetting up PCF for your CI Pipeline\n\n\nPivotal partners who have us host their pipeline have access to a pool of PCF\ninstances that are managed by us and are regularly updated with the latest\n(pre-)release versions of PCF. If you set up your own concourse server, you\nwill have to target your pipeline at a \nPCF instance you have setup\n.\n\n\nConcourse has a resource type to manage a pool of resources that are shared\nbetween pipelines, which is what we use to serialize PCF access between the\npartner pipelines that run on our concourse server.", 
            "title": "Continuous Integration"
        }, 
        {
            "location": "/concourse/#concourse-continuous-integration", 
            "text": "Cloud Foundry is a fast moving platform as we are constantly extending and\nenhancing it. When you integrate your software with Cloud Foundry, it is\nimportant to make sure that your integration continues to work with every\nnew release of the platform. A great way to ensure that is to set up a CI\npipeline for your tile against a PCF deployment that is constantly updated\nwith the latest Alpha release of the platform.  Our tool of choice for setting up CI is  concourse .\nWhile you are of course free to use whetever system you are familiar with,\nour tools and documentation are built to make concourse CI as easy as\npossible.", 
            "title": "Concourse Continuous Integration"
        }, 
        {
            "location": "/concourse/#setting-up-a-concourse-server", 
            "text": "You will need a concourse server to host your pipeline. If you partner with\nus, we have servers that can host your pipeline, and S3 storage that can be\nused to transfer artifacts to and from your servers. If you choose to set\nup your own, instructions can be found here:   Setting up concourse", 
            "title": "Setting up a Concourse Server"
        }, 
        {
            "location": "/concourse/#creating-a-concourse-pipeline-for-your-tile", 
            "text": "A typical CI pipeline for a tile consists of the following jobs:   Build the tile  Deploy it to PCF  Run a set of deployment tests to verify that it deployed and works correctly  Remove it from PCF   You describe this pipeline in a pipeline.yml file that is then uploaded to the\nconcourse server.  Tile Generator  contains a sample\npipeline that you can clone for your own tile.   We have provided a  docker image  to help you \nautomate your tile creation tasks via concourse. To make use of this image, you will want to do the following:   Declare a concourse resource for the tile source in your pipeline.yml file:   yml\n  - name: tile-source\n    type: git\n    source:\n      branch: master\n      uri: https://github.com/your-tile-project-repo \n1. Declare a resource to store the artifacts of your build process (for example, an aws s3 bucket) in your pipeline.yml file:  yml\n  - name: tile-build\n    type: s3\n    source:\n      access_key_id: your-aws-key-id-don't-check-this-in!\n      bucket: your-aws-bucket-name\n      regexp: .*-(?P version .*)\\.jar\n      secret_access_key: your-aws-access-key-don't-check-this-in! \n1. Declare a resource to store your tile in your pipeline.yml file:  yml\n  - name: tile\n    type: s3\n    source:\n      access_key_id: your-aws-key-id-don't-check-this-in!\n      bucket: your-aws-bucket-name\n      regexp: .*-(?P version .*)\\.pivotal\n      secret_access_key: your-aws-access-key-don't-check-this-in! \n1. Declare a resource to store a tile-history.yml file. This file is needed by the tile-generator process:  yml\n  - name: tile-history\n    type: s3\n    source:\n      access_key_id: your-aws-key-id-don't-check-this-in!\n      bucket: your-aws-bucket-name\n      regexp: tile-history-(?P version .*)\\.yml\n      secret_access_key: your-aws-access-key-don't-check-this-in! \n1. (Optional) consider managing the versioning of your project via  semver . If you decide to do this, add something like the following to your pipeline.yml file:  yml\n  - name: version\n    type: semver\n    source:\n      bucket: your-aws-bucket-name\n      key: current-version\n      access_key_id: your-aws-key-id-don't-check-this-in!\n      secret_access_key: your-aws-access-key-don't-check-this-in!\n      initial_version: 1.0.0 \n1. add a job such as the following, to your pipeline:  yml\n  - name: build-tile\n    serial_groups: [version]\n    plan:\n    - aggregate:\n      - get: tile-source\n      - get: tile-build\n      - get: version\n      - get: tile-history\n    - task: build-tile\n      file: tile-source/ci/build-tile/task.yml\n    - put: tile-history\n      params: {file: tile-history-new/*.yml}\n    - put: tile\n      params: {file: broker-tile/*.pivotal} \n1. define the tile build task via a task.yml file (per the above job configuration, this file would be added to the ci/build-tile directory in your source repository):  ```yml\n  platform: linux  image: docker:///cfplatformeng/tile-generator  inputs:\n  - name: tile-source\n  - name: tile-build\n  - name: version\n  - name: tile-history  outputs:\n  - name: tile\n  - name: tile-history-new  run:\n    path: tile-repo/ci/build-tile/task.sh\n```\n1. create a task.sh script to build the tile (per the above job configuration, this file would be added to the ci/build-tile directory in your source repository):  ```sh\n  #!/bin/sh -ex  cd tile-repo  cp ../../tile-build/* the-place-in-tile.yml-where-the-build-goes  ver= more ../version/number \n  tile build ${ver}  file= ls product/*.pivotal \n  filename=$(basename \"${file}\")\n  filename=\"${filename%-*}\"  cp ${file} ../tile/${filename}-${ver}.pivotal\n  cp tile-history.yml ../tile-history-new/tile-history-${ver}.yml\n  ``` \n1. string this job together with the other jobs in your pipeline (probably after a successful tile-build). The job will then build your tile and place it in your s3 bucket along with an updated tile-history file.", 
            "title": "Creating a Concourse Pipeline for your Tile"
        }, 
        {
            "location": "/concourse/#setting-up-pcf-for-your-ci-pipeline", 
            "text": "Pivotal partners who have us host their pipeline have access to a pool of PCF\ninstances that are managed by us and are regularly updated with the latest\n(pre-)release versions of PCF. If you set up your own concourse server, you\nwill have to target your pipeline at a  PCF instance you have setup .  Concourse has a resource type to manage a pool of resources that are shared\nbetween pipelines, which is what we use to serialize PCF access between the\npartner pipelines that run on our concourse server.", 
            "title": "Setting up PCF for your CI Pipeline"
        }, 
        {
            "location": "/tile-generator/", 
            "text": "Tile Generator\n\n\nThe Tile Generator is a tool to help you develop, package, test,\nand deploy services and other add-ons to Pivotal Cloud Foundry. Tiles are the\ninstallation package format used by Pivotal's Ops Manager to deploy these\ncomponents to both public and private cloud deployments. The tile generator\nuses templates and patterns that are based on years of experience integrating\nthird-party services into Cloud Foundry, and eliminates much of the need for\nyou to have intimate knowledge of all the tools involved.\n\n\n\n\nTile generator takes your software components, and a simple configuration file\nthat provides the minimal amount of information to describe and customize your\ntile. It then creates everything that's required to deploy your software into\nPivotal Cloud Foundry:\n\n\n\n\nBOSH errands\n to deploy and delete your software, including blue/green\n  deployments for zero-downtime upgrades\n\n\nA \nBOSH release\n suitable for deploying your software to the Elastic Runtime\n  or open-source Cloud Foundry\n\n\nA \nPivotal Ops Manager Tile\n that can be imported into Ops Manager, installed,\n  configured, and deployed, including UI forms and automatic upgrades from\n  previous versions\n\n\nA \nConcourse pipeline configuration\n to enable Continuous Integration of\n  your software with the latest versions of Pivotal Cloud Foundry\n\n\n\n\nUse the tile generator in combination with the \npcf utility\n\nto enable rapid deploy and test cycles of your software.\n\n\nThe current release of the tile generator supports tiles that have any\ncombination of the following package types:\n\n\n\n\nCloud Foundry Applications\n\n\nCloud Foundry Buildpacks\n\n\nCloud Foundry Service Brokers (both inside and outside the Elastic Runtime)\n\n\nDocker images (both inside and outside the Elastic Runtime)\n\n\n\n\nScreencast\n\n\nFor a 7-minute introduction into what tile generator is and does, see\n\nthis screencast\n.\n\n\nHow to Use\n\n\n\n\n\n\nInstall the tile-generator python package.\n   \nNote\n: tile-generator requires \nPython 2\n, and will \nnot\n work with Python 3.\n   We recommend using a\n   \nvirtualenv\n environment to\n   avoid conflicts with other Python packages:\n\n\nvirtualenv -p python2 tile-generator\nsource tile-generator/bin/activate\npip install tile-generator\n\n\n\nThis will put the \ntile\n and \npcf\n commands in your \nPATH\n.\n\n\n\n\n\n\nInstall the \nBOSH CLI\n\n\n\n\n\n\nThen, from within the root directory of the project for which you wish to create a tile, initialize it as a tile repo (we recommend that this be a git repo, but this is not required):\n\n\ncd \nyour project dir\n\ntile init\n\n\n\n\n\n\n\nEdit the generated \ntile.yml\n file to define your tile (more details below)\n\n\n\n\n\n\nBuild your tile\n\n\ntile build\n\n\n\n\n\n\n\nThe generator will first create a BOSH release (in the \nrelease\n subdirectory),\nthen wrap that release into a Pivotal tile (in the \nproduct\n subdirectory).\nIf required for the installation, it will automatically pull down the latest\nrelease version of the Cloud Foundry CLI.\n\n\nTile generator is also available pre-installed in a docker image on\n\nDocker Hub\n.\nThis image contains the tile-generator \ntile\n and \npcf\n commands, all the\nnecessary Python dependencies, as well as the BOSH CLI.\n\n\nYou can use this in Concourse pipelines by specifying it as the base image\nfor your tasks:\n\n\n  - task: tile-build\n    config:\n      platform: linux\n      image: cfplatformeng/tile-generator\n\n\n\n\nOr you can derive your own docker images from this one by using it as the base\nimage in your Dockerfile:\n\n\nFROM cfplatformeng/tile-generator\n\n\n\n\nBuilding the Sample\n\n\nThe repository includes a sample tile that exercises most of the features of the\ntile generator (it is used by the CI pipeline to verify that things work correctly).\nYou can build this sample using the following steps:\n\n\ncd sample\nsrc/build.sh\ntile build\n\n\n\n\n\n\nNote:\n\n\nThe sample tile includes a Python application that is re-used in several packages,\nsometimes as an app, sometimes as a service broker. One of the deployments (app3)\nuses the sample application inside a docker image that is currently only modified\nby the CI pipeline. If you modify the sample app, you will have to build your own\ndocker image using the provided \nDockerfile\n and change the image name in\n\nsample/tile.yml\n to include the modified code in app3.\n\n\n\n\nDefining your Tile\n\n\nAll required configuration for your tile is in the file called \ntile.yml\n.\n\ntile init\n will create an initial version for you that can serve as a template.\nThe first section in the file describes the general properties of your tile:\n\n\nname: tile-name # By convention lowercase with dashes\nicon_file: resources/icon.png\nlabel: Brief Text for the Tile Icon\ndescription: Longer description of the tile's purpose\n\n\n\n\nThe \nicon_file\n should be a 128x128 pixel image that will appear on your tile in\nthe Ops Manager GUI. By convention, any resources used by the tile should be\nplaced in the \nresources\n sub-directory of your repo, although this is not\nmandatory. The \nlabel\n text will appear on the tile under your icon.\n\n\nPackages\n\n\nNext you can specify the packages to be included in your tile. The format of\neach package entry depends on the type of package you are adding.\n\n\nPushed Applications\n\n\nApplications (including service brokers) that are being \ncf push\ned into the\nElastic Runtime use the following format:\n\n\n- name: my-application\n  type: app # or app-broker\n  manifest:\n    # any options that you would normally specify in a cf manifest.yml, including\n/i\n\n    buildpack:\n    command:\n    domain:\n    host:\n    instances:\n    memory:\n    path:\n    env:\n    services:\n  health_check: none                 # optional\n  configurable_persistence: true     # optional\n  needs_cf_credentials: true         # optional\n  auto_services: p-mysql p-redis     # optional\n\n\n\n\nNote: for applications that are normally pushed as multiple files (node.js for example)\nyou should zip up the project files plus all dependencies into a single zip file, then\nedit tile.yml to point to the zipped file:\n\n\ncd \nyour project dir\n\nzip -r resources/\nyour project name\n.zip \nlist of file and dirs to include in the zip\n\n\n\n\n\nIf your application is a service broker, use \napp-broker\n as the type instead of just\n\napp\n. The application will then automatically be registered as a broker on install,\nand deleted on uninstall.\n\n\nhealth_check\n lets you configure the value of the cf cli \n--health_check_type\n\noption. Expect this option to move into the manifest as soon as CF supports it there.\nCurrently, the only valid options are \nnone\n and \nport\n.\n\n\nconfigurable_persistence: true\n results in the user being able to select a backing\nservice for data persistence. If there is a specific broker you want to use, you can\nuse the \nauto-services\n feature described below. If you want to bind to an already\nexisting service instance, use the \nservices\n proeprty of the \nmanifest\n instead.\n\n\nneeds_cf_credentials\n causes the application to receive two additional environment\nvariables named \nCF_ADMIN_USER\n and \nCF_ADMIN_PASSWORD\n with the admin credentials\nfor the Elastic Runtime into which they are being deployed. This allows apps and\nservices to interact with the Cloud Controller.\n\n\nauto_services\n is described in more detail below.\n\n\nService Brokers\n\n\nMost modern service brokers are pushed into the Elastic Runtime as normal\nCF applications. For these types of brokers, use the Pushed Application format\nspecified above, but set the type to \napp-broker\n or \ndocker-app-broker\n instead\nof just \napp\n or \ndocker-app\n:\n\n\n- name: my-broker\n  type: app-broker\n  manifest:\n    command:\n    domain:\n    path:\n    # ...\n  needs_cf_credentials: true           # optional\n  auto_services: p-mysql p-redis       # optional\n  enable_global_access_to_plans: true  # optional\n\n\n\n\n\n\nNote:\n\n\nUnless you specify the \nenable_global_access_to_plans: true\n option, your\nbroker's services will not appear in the user's marketplaces.\nOperators will have to use the \ncf enable-service-access\n command to allow\nspecific users, orgs, and spaces to access your services.\n\n\n\n\nYour broker will be automatically registered with the Cloud Controller. The\nCloud Controller will invoke your broker's endpoints, and it will use basic\nauthentication to secure those API calls. The credentials it will use are\npassed to your broker in two environment variables:\n\n\nSECURITY_USER_NAME\nSECURITY_USER_PASSWORD\n\n\n\n\nYour broker is expected to accept those credentials. If it doesn't, automatic\nbroker registration will fail.\n\n\nSome service brokers support operator-defined service plans, for instance when\nthe plans reflect customer license keys. To allow operators to add plans from\nthe tile configuration, add the following section at the top level of your tile.yml:\n\n\nservice_plan_forms:\n- name: service_plans_1\n  label: Service 1 Plans\n  description: Specify the plans you want Service 1 to offer\n  properties:\n  - name: description\n    type: string\n    description: \nSome Description\n\n    configurable: true\n  - name: license_key1\n    type: string\n    configurable: true\n    description: The license key for this plan\n  - name: num_seats1\n    type: integer\n    configurable: true\n    description: The number of available seats for this license\n    default: 1\n    constraints:\n      min: 1\n      max: 500\n\n\n\n\nName and GUID fields will be supplied by default for each plan, but all other fields\nare optional and customizable. Multiple forms are supported. The operator-configured\nplans will be passed to your service broker in JSON format in an environment variable\nnamed after your form but in ALL CAPS (in this case \nSERVICE_PLANS_1\n).\n\n\nFor an external service broker, use:\n\n\n- name: my-application\n  type: external-broker\n  uri: http://broker3.example.com\n  username: user\n  password: #secret\n  internal_service_names: 'service1,service2'\n\n\n\n\nBosh Releases\n\n\nYou can include \nBOSH releases\n in\nyour tile with the \nbosh-release\n package type. For example, here is a\npackage definition to include a Redis BOSH release:\n\n\n- name: redis\n  type: bosh-release\n  path: resources/redis-12+dev.1.tgz\n  jobs:\n  - name: redis_leader_z1\n    templates:\n    - name: redis\n      release: redis\n    memory: 512\n    ephemeral_disk: 4096\n    persistent_disk: 4096\n    cpu: 2\n    static_ip: 1\n    max_in_flight: 1\n    properties:\n      network: redis1\n      redis:\n        password: red!s\n  - name: redis_z1\n    templates:\n    - name: redis\n      release: redis\n    instances: 2\n    memory: 512\n    ephemeral_disk: 4096\n    persistent_disk: 4096\n    cpu: 2\n    static_ip: 1\n    properties:\n      network: redis1\n      redis:\n        master: (( .redis_leader_z1.first_ip ))\n        password: red!s\n  - name: redis_test_slave_z1\n    templates:\n    - name: redis\n      release: redis\n    instances: 1\n    memory: 512\n    ephemeral_disk: 4096\n    persistent_disk: 4096\n    cpu: 2\n    static_ip: 1\n    properties:\n      network: redis1\n      redis:\n        master: (( .redis_leader_z1.first_ip ))\n        password: red!s\n  - name: acceptance-tests\n    templates:\n    - name: acceptance-tests\n      release: redis\n    lifecycle: errand\n    post_deploy: true\n    memory: 512\n    ephemeral_disk: 4096\n    persistent_disk: 0\n    cpu: 2\n    dynamic_ip: 1\n    properties:\n      redis:\n        master: (( .redis_leader_z1.first_ip ))\n        password: red!s\n        slave: (( .redis_test_slave_z1.first_ip ))\n\n\n\n\nBuildpacks\n\n\n- name: my-buildpack\n  type: buildpack\n  path: resources/buildpack.zip\n  buildpack_order: 99     # optional, 99 means end of the list\n\n\n\n\nDocker Images\n\n\nApplications packages as docker images can be deployed inside or outside the Elastic\nRuntime. To push a docker image as a CF application, use the \nPushed Application\n\nformat specified above, but use the \ndocker-app\n or \ndocker-app-broker\n type instead\nof just \napp\n or \napp-broker\n. The docker image to be used is then specified using\nthe \nimage\n property:\n\n\n- name: app1\n  type: docker-app\n  image: test/dockerimage\n  manifest:\n    ...\n\n\n\n\nIf this app is also a service broker, use \ndocker-app-broker\n instead of just\n\ndocker-app\n. This option is appropriate for docker-wrapped 12-factor apps that\ndelegate their persistence to bound services.\n\n\nDocker applications that require persistent storage can not be deployed into\nthe Elastic Runtime. These can be deployed to separate BOSH-managed VMs instead\nby using the \ndocker-bosh\n type:\n\n\n- name: docker-bosh1\n  type: docker-bosh\n  cpu: 5\n  memory: 4096\n  ephemeral_disk: 4096\n  persistent_disk: 2048\n  instances: 1\n  manifest: |\n    containers:\n    - name: redis\n      image: \nredis\n\n      command: \n--dir /var/lib/redis/ --appendonly yes\n\n      bind_ports:\n      - \n6379:6379\n\n      bind_volumes:\n      - \n/var/lib/redis\n\n      entrypoint: \nredis-server\n\n      memory: \n256m\n\n      env_vars:\n      - \nEXAMPLE_VAR=1\n\n    - name: mysql\n      image: \ngoogle/mysql\n\n      bind_ports:\n      - \n3306:3306\n\n      bind_volumes:\n      - \n/mysql\n\n    - name: elasticsearch\n      image: \nbosh/elasticsearch\n\n      links:\n      - mysql:db\n      depends_on:\n      - mysql\n      bind_ports:\n      - \n9200:9200\n\n\n\n\n\nIf a docker image cannot be downloaded by BOSH dynamically, its better to provide a ready made docker image and package it as part of the BOSH release. In that case, specify the image as a local file.\n\n\n- name: docker-bosh2\n  type: docker-bosh\n  files:\n  - path: resources/cfplatformeng-docker-tile-example.tgz\n  cpu: 5\n  memory: 4096\n  ephemeral_disk: 4096\n  persistent_disk: 2048\n  instances: 1\n  manifest: |\n    containers:\n    - name: test_docker_image\n      image: \ncfplatformeng/docker-tile-example\n\n      env_vars:\n      - \nEXAMPLE_VAR=1\n\n      # See below on custom forms/variables and binding it to the docker env variable\n      - \ncustom_variable_name=((.properties.customer_name.value))\n\n\n\n\n\nCustom Forms and Properties\n\n\nYou can pass custom properties to all applications deployed by your tile by adding\nthe to the properties section of \ntile.yml\n:\n\n\nproperties:\n- name: author\n  type: string\n  label: Author\n  value: Tile Ninja\n\n\n\n\nIf you want the properties to be configurable by the tile installer, place them on\na custom form instead:\n\n\nforms:\n- name: custom-form1\n  label: Test Tile\n  description: Custom Properties for Test Tile\n  properties:\n  - name: customer_name\n    type: string\n    label: Full Name\n  - name: street_address\n    type: string\n    label: Street Address\n    description: Address to use for junk mail\n  - name: city\n    type: string\n    label: City\n  - name: zip_code\n    type: string\n    label: ZIP+4\n    default: '90310'\n  - name: country\n    type: dropdown_select\n    label: Country\n    options:\n    - name: country_us\n      label: US\n      default: true\n    - name: country_elsewhere\n      label: Elsewhere\n- name: account-info-1\n  label: Account Info\n  description: Example Account Information Form\n  properties:\n  - name: username\n    type: string\n    label: Username\n  - name: password\n    type: secret\n    label: Password\n\n\n\n\nProperties defined in either section will be passed to all pushed applications\nas environment variables (the name of the environment variable will be the same\nas the property name but in ALL_CAPS). They can also be referenced in other parts\nof the configuration file by using \n(( .properties.\nproperty-name\n ))\n instead\nof a hardcoded value.\n\n\nAll properties supported by Ops Manager may be used. The syntax is the same\nas used by Ops Manager, except that for simplicity property blueprints for\nform fields do not need to be declared separately. Instead, the declaration\nis included in the form itself. For a complete list of supported property\ntypes and syntax, see the\n\nOps Manager Product Template Reference\n.\n\n\nProperties of type \nsecret\n will have their value hidden on the forms, and\nobfuscated in the installation logs (all but the first two characters will be\nreplaced by \n*****\n). But their value will be passed to your applications in\nplain text as all other value types.\n\n\nAutomatic Provisioning of Services\n\n\nTile generator automates the provisioning of services. Any application (including\nservice brokers and docker-based applications) that are being pushed into the\nElastic Runtime can automatically be bound to services through the \nauto_services\n\nfeature:\n\n\n- name: app1\n  type: app\n  auto_services:\n  - name: p-mysql\n    plan: 100mb-dev\n  - name: p-redis\n\n\n\n\nYou can specify any number of service names, optionally specifying a specific\nplan. During deployment, the generated tile will create an instance of each\nservice if one does not already exist, and then bind that instance to your\npackage.\n\n\nService instances provisioned this way survive updates, but will be deleted\nwhen the tile is uninstalled.\n\n\n\n\nNote:\n\n\nThe name is the name of the provided \nservice, not the broker\n.\nIn many cases these are not the same, and a single broker may even offer\nmultiple services. Use \ncf service-access\n to see the services and plans\noffered by installed service brokers.\n\n\n\n\nIf you do not specify a plan, the tile generator will use the first plan\nlisted for the service in the broker catalog. It is a good idea to always\nspecify a service plan. If you \nchange\n the plan between versions of your\ntile, the tile generator will attempt to update the plan while preserving\nthe service (thus not causing data loss during upgrade). If the service\ndoes not support plan changes, this will cause the upgrade to fail.\n\n\nconfigurable_persistence\n is really just a special case of \nauto_services\n,\nletting the user choose between some standard brokers.\n\n\nDeclaring Product Dependencies\n\n\nWhen your product has dependencies on others, you can have Ops Manager\nenforce that dependency by declaring it in your \ntile.yml\n file as follows:\n\n\nrequires_product_versions:\n- name: p-mysql\n  version: '~\n 1.7'\n\n\n\n\nIf the required product is not present in the PCF installation, Ops Manager\nwill display a message saying\n\nyour-tile\n requires 'p-mysql' version '~\n 1.7' as a dependency\n, and will\nrefuse to install your tile until that dependency is satisfied.\n\n\nWhen using automatic provisioning of services as described above, it is\noften appropriate to add those products as a dependency. Tile generator can\nnot do this automatically as it can't always determine which product provides\nthe requested service.\n\n\nOrgs and Spaces\n\n\nBy default, the tile generator will create a single new org and space for any\npackages that install into the Elastic Runtime, using the name of the tile and\nappending \n-org\n and \n-space\n, respectively. The default memory quota for a\nnewly created or will be 1024 (1G). You can change any of these defaults by\nspecifying the following properties in \ntile.yml\n:\n\n\norg: test-org\norg_quota: 4096\nspace: test-space\n\n\n\n\nSecurity\n\n\nIf your cf packages need outbound access (including access to other packages\nwithin the same tile), you will need to apply an appropriate security group.\nThe following option will remove all constraints on outbound traffic:\n\n\napply_open_security_group: true\n\n\n\n\nStemcells\n\n\nThe tile generator will default to a recent stemcell supported by Ops Manager.\nIn most cases the default will be fine, as the stemcell is only used to execute\nCF command lines and/or the docker daemon. But if you have specific stemcell\nrequirements, you can override the defaults in your \ntile.yml\n file by including\na \nstemcell-criteria\n section and replacing the appopriate values:\n\n\nstemcell_criteria:\n  os: 'ubunty-trusty'\n  version: '3146.5'     #NOTE: You must quote the version to force the type to be string\n\n\n\n\nCustom Errands\n\n\nTile generator supplies standard errands to deploy and delete CF type packages. You can\nreplace or augment those errands by specifying errand shell commands in your tile.yml\nfile. For example:\n\n\npackages:\n- name: meta-buildpack\n  type: buildpack\n  buildpack_order: 0 # Go to head of list\n  path: meta_buildpack.zip\n  deploy: |\n    cp meta_buildpack.zip meta_buildpack-v{{context.version}}.zip\n    existing=`cf buildpacks | grep '^meta_buildpack'`\n    if [ -z \n$existing\n ]; then\n      cf create-buildpack meta_buildpack meta_buildpack-v{{context.version}}.zip 0\n    else\n      semver=`echo \n$existing\n | sed 's/.* meta_buildpack-v\\(.*\\)\\.zip/\\1/'`\n      if is_newer \n{{context.version}}\n \n$semver\n; then\n        cf update-buildpack meta_buildpack -p meta_buildpack-v{{context.version}}.zip\n      else\n        echo \nNewer version ($semver) of meta_buildpack is already present\n\n      fi\n      cf update-buildpack meta_buildpack -i 0\n    fi\n  delete: |\n    # Intentional no-op, as others may have a dependency on this\n\n\n\n\ndeploy\n and \ndelete\n will completely replace the standard errand commands for the\npackage in which you include them. If you want to keep the standard commands, but\nadd additional commands to execute before or after the standard errand, use\n\npre_deploy\n, \npost_deploy\n, \npre_delete\n, and/or \npost_delete\n instead.\n\n\nVersioning\n\n\nThe tile generator uses \nsemver versioning\n. By default, \ntile build\n will\ngenerate the next patch release. Major and minor releases can be generated\nby explicitly specifying \ntile build major\n or \ntile build minor\n. Or to\noverride the version number completely, specify a valid semver version on\nthe build command, e.g. \ntile build 3.4.5\n.\n\n\nNo-op content migration rules are generated for every prior release to the\ncurrent release, so that Ops Manager will allow tile upgrades from any\nversion to any newer version. This depends on the existence of the file\n\ntile-history.yml\n. In a pinch, if you need to be able to upgrade from a\nrandom old version to a new one, you can edit that file, or do:\n\n\ntile build \nold-version\n\ntile build \nnew-version\n\n\n\n\n\nThe new tile will then support upgrades from \nold-version\n.\n\n\n \n\n\nUpgrades\n\n\nBy default, tile generator produces all code necessary to do a blue/green,\nzero-downtime deployment of all tile components when installing a newer version\nover an older one. For most tile versions this will be all that is needed.\n\n\nOps Manager has support for performing upgrade actions, like database migrations,\nduring a tile upgrade, but this capability is not yet exposed through tile\ngenerator.\n\n\nExample\n\n\n$ tile build\nname: tibco-bwce\nicon: icon.png\nlabel: TIBCO BusinessWorks Container Edition\ndescription: BusinessWorks edition that supports deploying to Cloud Foundry\nversion: 0.0.2\n\nbosh init release\nbosh generate package cf_cli\nbosh generate package bwce_buildpack\nbosh generate job install_bwce_buildpack\nbosh generate job remove_bwce_buildpack\nbosh create release --final --with-tarball --version 0.0.2\n\ntile generate release\ntile generate metadata\ntile generate errand install_bwce_buildpack\ntile generate errand remove_bwce_buildpack\ntile generate content-migrations\n\ncreated tile tibco-bwce-0.0.2.pivotal\n\n\n\n\nThis tile includes a single large buildpack, and takes less than 15 seconds\nto build including the CF CLI download and the BOSH release generation.\n\n\nSupported Commands\n\n\ntile init [\ntile-name\n]\ntile build [patch|minor|major|\nversion\n]\n\n\n\n\nCredits\n\n\n\n\nsparameswaran\n supplied most of the actual template content, originally built as part of \ncf-platform-eng/bosh-generic-sb-release\n\n\nfrodenas\n contributed most of the docker content through \ncloudfoundry-community/docker-boshrelease\n\n\njoshuamckenty\n suggested the jinja template approach he employed in \nopencontrol", 
            "title": "Tile Generator"
        }, 
        {
            "location": "/tile-generator/#tile-generator", 
            "text": "The Tile Generator is a tool to help you develop, package, test,\nand deploy services and other add-ons to Pivotal Cloud Foundry. Tiles are the\ninstallation package format used by Pivotal's Ops Manager to deploy these\ncomponents to both public and private cloud deployments. The tile generator\nuses templates and patterns that are based on years of experience integrating\nthird-party services into Cloud Foundry, and eliminates much of the need for\nyou to have intimate knowledge of all the tools involved.   Tile generator takes your software components, and a simple configuration file\nthat provides the minimal amount of information to describe and customize your\ntile. It then creates everything that's required to deploy your software into\nPivotal Cloud Foundry:   BOSH errands  to deploy and delete your software, including blue/green\n  deployments for zero-downtime upgrades  A  BOSH release  suitable for deploying your software to the Elastic Runtime\n  or open-source Cloud Foundry  A  Pivotal Ops Manager Tile  that can be imported into Ops Manager, installed,\n  configured, and deployed, including UI forms and automatic upgrades from\n  previous versions  A  Concourse pipeline configuration  to enable Continuous Integration of\n  your software with the latest versions of Pivotal Cloud Foundry   Use the tile generator in combination with the  pcf utility \nto enable rapid deploy and test cycles of your software.  The current release of the tile generator supports tiles that have any\ncombination of the following package types:   Cloud Foundry Applications  Cloud Foundry Buildpacks  Cloud Foundry Service Brokers (both inside and outside the Elastic Runtime)  Docker images (both inside and outside the Elastic Runtime)", 
            "title": "Tile Generator"
        }, 
        {
            "location": "/tile-generator/#screencast", 
            "text": "For a 7-minute introduction into what tile generator is and does, see this screencast .", 
            "title": "Screencast"
        }, 
        {
            "location": "/tile-generator/#how-to-use", 
            "text": "Install the tile-generator python package.\n    Note : tile-generator requires  Python 2 , and will  not  work with Python 3.\n   We recommend using a\n    virtualenv  environment to\n   avoid conflicts with other Python packages:  virtualenv -p python2 tile-generator\nsource tile-generator/bin/activate\npip install tile-generator  This will put the  tile  and  pcf  commands in your  PATH .    Install the  BOSH CLI    Then, from within the root directory of the project for which you wish to create a tile, initialize it as a tile repo (we recommend that this be a git repo, but this is not required):  cd  your project dir \ntile init    Edit the generated  tile.yml  file to define your tile (more details below)    Build your tile  tile build    The generator will first create a BOSH release (in the  release  subdirectory),\nthen wrap that release into a Pivotal tile (in the  product  subdirectory).\nIf required for the installation, it will automatically pull down the latest\nrelease version of the Cloud Foundry CLI.  Tile generator is also available pre-installed in a docker image on Docker Hub .\nThis image contains the tile-generator  tile  and  pcf  commands, all the\nnecessary Python dependencies, as well as the BOSH CLI.  You can use this in Concourse pipelines by specifying it as the base image\nfor your tasks:    - task: tile-build\n    config:\n      platform: linux\n      image: cfplatformeng/tile-generator  Or you can derive your own docker images from this one by using it as the base\nimage in your Dockerfile:  FROM cfplatformeng/tile-generator", 
            "title": "How to Use"
        }, 
        {
            "location": "/tile-generator/#building-the-sample", 
            "text": "The repository includes a sample tile that exercises most of the features of the\ntile generator (it is used by the CI pipeline to verify that things work correctly).\nYou can build this sample using the following steps:  cd sample\nsrc/build.sh\ntile build   Note:  The sample tile includes a Python application that is re-used in several packages,\nsometimes as an app, sometimes as a service broker. One of the deployments (app3)\nuses the sample application inside a docker image that is currently only modified\nby the CI pipeline. If you modify the sample app, you will have to build your own\ndocker image using the provided  Dockerfile  and change the image name in sample/tile.yml  to include the modified code in app3.", 
            "title": "Building the Sample"
        }, 
        {
            "location": "/tile-generator/#defining-your-tile", 
            "text": "All required configuration for your tile is in the file called  tile.yml . tile init  will create an initial version for you that can serve as a template.\nThe first section in the file describes the general properties of your tile:  name: tile-name # By convention lowercase with dashes\nicon_file: resources/icon.png\nlabel: Brief Text for the Tile Icon\ndescription: Longer description of the tile's purpose  The  icon_file  should be a 128x128 pixel image that will appear on your tile in\nthe Ops Manager GUI. By convention, any resources used by the tile should be\nplaced in the  resources  sub-directory of your repo, although this is not\nmandatory. The  label  text will appear on the tile under your icon.", 
            "title": "Defining your Tile"
        }, 
        {
            "location": "/tile-generator/#packages", 
            "text": "Next you can specify the packages to be included in your tile. The format of\neach package entry depends on the type of package you are adding.", 
            "title": "Packages"
        }, 
        {
            "location": "/tile-generator/#pushed-applications", 
            "text": "Applications (including service brokers) that are being  cf push ed into the\nElastic Runtime use the following format:  - name: my-application\n  type: app # or app-broker\n  manifest:\n    # any options that you would normally specify in a cf manifest.yml, including /i \n    buildpack:\n    command:\n    domain:\n    host:\n    instances:\n    memory:\n    path:\n    env:\n    services:\n  health_check: none                 # optional\n  configurable_persistence: true     # optional\n  needs_cf_credentials: true         # optional\n  auto_services: p-mysql p-redis     # optional  Note: for applications that are normally pushed as multiple files (node.js for example)\nyou should zip up the project files plus all dependencies into a single zip file, then\nedit tile.yml to point to the zipped file:  cd  your project dir \nzip -r resources/ your project name .zip  list of file and dirs to include in the zip   If your application is a service broker, use  app-broker  as the type instead of just app . The application will then automatically be registered as a broker on install,\nand deleted on uninstall.  health_check  lets you configure the value of the cf cli  --health_check_type \noption. Expect this option to move into the manifest as soon as CF supports it there.\nCurrently, the only valid options are  none  and  port .  configurable_persistence: true  results in the user being able to select a backing\nservice for data persistence. If there is a specific broker you want to use, you can\nuse the  auto-services  feature described below. If you want to bind to an already\nexisting service instance, use the  services  proeprty of the  manifest  instead.  needs_cf_credentials  causes the application to receive two additional environment\nvariables named  CF_ADMIN_USER  and  CF_ADMIN_PASSWORD  with the admin credentials\nfor the Elastic Runtime into which they are being deployed. This allows apps and\nservices to interact with the Cloud Controller.  auto_services  is described in more detail below.", 
            "title": "Pushed Applications"
        }, 
        {
            "location": "/tile-generator/#service-brokers", 
            "text": "Most modern service brokers are pushed into the Elastic Runtime as normal\nCF applications. For these types of brokers, use the Pushed Application format\nspecified above, but set the type to  app-broker  or  docker-app-broker  instead\nof just  app  or  docker-app :  - name: my-broker\n  type: app-broker\n  manifest:\n    command:\n    domain:\n    path:\n    # ...\n  needs_cf_credentials: true           # optional\n  auto_services: p-mysql p-redis       # optional\n  enable_global_access_to_plans: true  # optional   Note:  Unless you specify the  enable_global_access_to_plans: true  option, your\nbroker's services will not appear in the user's marketplaces.\nOperators will have to use the  cf enable-service-access  command to allow\nspecific users, orgs, and spaces to access your services.   Your broker will be automatically registered with the Cloud Controller. The\nCloud Controller will invoke your broker's endpoints, and it will use basic\nauthentication to secure those API calls. The credentials it will use are\npassed to your broker in two environment variables:  SECURITY_USER_NAME\nSECURITY_USER_PASSWORD  Your broker is expected to accept those credentials. If it doesn't, automatic\nbroker registration will fail.  Some service brokers support operator-defined service plans, for instance when\nthe plans reflect customer license keys. To allow operators to add plans from\nthe tile configuration, add the following section at the top level of your tile.yml:  service_plan_forms:\n- name: service_plans_1\n  label: Service 1 Plans\n  description: Specify the plans you want Service 1 to offer\n  properties:\n  - name: description\n    type: string\n    description:  Some Description \n    configurable: true\n  - name: license_key1\n    type: string\n    configurable: true\n    description: The license key for this plan\n  - name: num_seats1\n    type: integer\n    configurable: true\n    description: The number of available seats for this license\n    default: 1\n    constraints:\n      min: 1\n      max: 500  Name and GUID fields will be supplied by default for each plan, but all other fields\nare optional and customizable. Multiple forms are supported. The operator-configured\nplans will be passed to your service broker in JSON format in an environment variable\nnamed after your form but in ALL CAPS (in this case  SERVICE_PLANS_1 ).  For an external service broker, use:  - name: my-application\n  type: external-broker\n  uri: http://broker3.example.com\n  username: user\n  password: #secret\n  internal_service_names: 'service1,service2'", 
            "title": "Service Brokers"
        }, 
        {
            "location": "/tile-generator/#bosh-releases", 
            "text": "You can include  BOSH releases  in\nyour tile with the  bosh-release  package type. For example, here is a\npackage definition to include a Redis BOSH release:  - name: redis\n  type: bosh-release\n  path: resources/redis-12+dev.1.tgz\n  jobs:\n  - name: redis_leader_z1\n    templates:\n    - name: redis\n      release: redis\n    memory: 512\n    ephemeral_disk: 4096\n    persistent_disk: 4096\n    cpu: 2\n    static_ip: 1\n    max_in_flight: 1\n    properties:\n      network: redis1\n      redis:\n        password: red!s\n  - name: redis_z1\n    templates:\n    - name: redis\n      release: redis\n    instances: 2\n    memory: 512\n    ephemeral_disk: 4096\n    persistent_disk: 4096\n    cpu: 2\n    static_ip: 1\n    properties:\n      network: redis1\n      redis:\n        master: (( .redis_leader_z1.first_ip ))\n        password: red!s\n  - name: redis_test_slave_z1\n    templates:\n    - name: redis\n      release: redis\n    instances: 1\n    memory: 512\n    ephemeral_disk: 4096\n    persistent_disk: 4096\n    cpu: 2\n    static_ip: 1\n    properties:\n      network: redis1\n      redis:\n        master: (( .redis_leader_z1.first_ip ))\n        password: red!s\n  - name: acceptance-tests\n    templates:\n    - name: acceptance-tests\n      release: redis\n    lifecycle: errand\n    post_deploy: true\n    memory: 512\n    ephemeral_disk: 4096\n    persistent_disk: 0\n    cpu: 2\n    dynamic_ip: 1\n    properties:\n      redis:\n        master: (( .redis_leader_z1.first_ip ))\n        password: red!s\n        slave: (( .redis_test_slave_z1.first_ip ))", 
            "title": "Bosh Releases"
        }, 
        {
            "location": "/tile-generator/#buildpacks", 
            "text": "- name: my-buildpack\n  type: buildpack\n  path: resources/buildpack.zip\n  buildpack_order: 99     # optional, 99 means end of the list", 
            "title": "Buildpacks"
        }, 
        {
            "location": "/tile-generator/#docker-images", 
            "text": "Applications packages as docker images can be deployed inside or outside the Elastic\nRuntime. To push a docker image as a CF application, use the  Pushed Application \nformat specified above, but use the  docker-app  or  docker-app-broker  type instead\nof just  app  or  app-broker . The docker image to be used is then specified using\nthe  image  property:  - name: app1\n  type: docker-app\n  image: test/dockerimage\n  manifest:\n    ...  If this app is also a service broker, use  docker-app-broker  instead of just docker-app . This option is appropriate for docker-wrapped 12-factor apps that\ndelegate their persistence to bound services.  Docker applications that require persistent storage can not be deployed into\nthe Elastic Runtime. These can be deployed to separate BOSH-managed VMs instead\nby using the  docker-bosh  type:  - name: docker-bosh1\n  type: docker-bosh\n  cpu: 5\n  memory: 4096\n  ephemeral_disk: 4096\n  persistent_disk: 2048\n  instances: 1\n  manifest: |\n    containers:\n    - name: redis\n      image:  redis \n      command:  --dir /var/lib/redis/ --appendonly yes \n      bind_ports:\n      -  6379:6379 \n      bind_volumes:\n      -  /var/lib/redis \n      entrypoint:  redis-server \n      memory:  256m \n      env_vars:\n      -  EXAMPLE_VAR=1 \n    - name: mysql\n      image:  google/mysql \n      bind_ports:\n      -  3306:3306 \n      bind_volumes:\n      -  /mysql \n    - name: elasticsearch\n      image:  bosh/elasticsearch \n      links:\n      - mysql:db\n      depends_on:\n      - mysql\n      bind_ports:\n      -  9200:9200   If a docker image cannot be downloaded by BOSH dynamically, its better to provide a ready made docker image and package it as part of the BOSH release. In that case, specify the image as a local file.  - name: docker-bosh2\n  type: docker-bosh\n  files:\n  - path: resources/cfplatformeng-docker-tile-example.tgz\n  cpu: 5\n  memory: 4096\n  ephemeral_disk: 4096\n  persistent_disk: 2048\n  instances: 1\n  manifest: |\n    containers:\n    - name: test_docker_image\n      image:  cfplatformeng/docker-tile-example \n      env_vars:\n      -  EXAMPLE_VAR=1 \n      # See below on custom forms/variables and binding it to the docker env variable\n      -  custom_variable_name=((.properties.customer_name.value))", 
            "title": "Docker Images"
        }, 
        {
            "location": "/tile-generator/#custom-forms-and-properties", 
            "text": "You can pass custom properties to all applications deployed by your tile by adding\nthe to the properties section of  tile.yml :  properties:\n- name: author\n  type: string\n  label: Author\n  value: Tile Ninja  If you want the properties to be configurable by the tile installer, place them on\na custom form instead:  forms:\n- name: custom-form1\n  label: Test Tile\n  description: Custom Properties for Test Tile\n  properties:\n  - name: customer_name\n    type: string\n    label: Full Name\n  - name: street_address\n    type: string\n    label: Street Address\n    description: Address to use for junk mail\n  - name: city\n    type: string\n    label: City\n  - name: zip_code\n    type: string\n    label: ZIP+4\n    default: '90310'\n  - name: country\n    type: dropdown_select\n    label: Country\n    options:\n    - name: country_us\n      label: US\n      default: true\n    - name: country_elsewhere\n      label: Elsewhere\n- name: account-info-1\n  label: Account Info\n  description: Example Account Information Form\n  properties:\n  - name: username\n    type: string\n    label: Username\n  - name: password\n    type: secret\n    label: Password  Properties defined in either section will be passed to all pushed applications\nas environment variables (the name of the environment variable will be the same\nas the property name but in ALL_CAPS). They can also be referenced in other parts\nof the configuration file by using  (( .properties. property-name  ))  instead\nof a hardcoded value.  All properties supported by Ops Manager may be used. The syntax is the same\nas used by Ops Manager, except that for simplicity property blueprints for\nform fields do not need to be declared separately. Instead, the declaration\nis included in the form itself. For a complete list of supported property\ntypes and syntax, see the Ops Manager Product Template Reference .  Properties of type  secret  will have their value hidden on the forms, and\nobfuscated in the installation logs (all but the first two characters will be\nreplaced by  ***** ). But their value will be passed to your applications in\nplain text as all other value types.", 
            "title": "Custom Forms and Properties"
        }, 
        {
            "location": "/tile-generator/#automatic-provisioning-of-services", 
            "text": "Tile generator automates the provisioning of services. Any application (including\nservice brokers and docker-based applications) that are being pushed into the\nElastic Runtime can automatically be bound to services through the  auto_services \nfeature:  - name: app1\n  type: app\n  auto_services:\n  - name: p-mysql\n    plan: 100mb-dev\n  - name: p-redis  You can specify any number of service names, optionally specifying a specific\nplan. During deployment, the generated tile will create an instance of each\nservice if one does not already exist, and then bind that instance to your\npackage.  Service instances provisioned this way survive updates, but will be deleted\nwhen the tile is uninstalled.   Note:  The name is the name of the provided  service, not the broker .\nIn many cases these are not the same, and a single broker may even offer\nmultiple services. Use  cf service-access  to see the services and plans\noffered by installed service brokers.   If you do not specify a plan, the tile generator will use the first plan\nlisted for the service in the broker catalog. It is a good idea to always\nspecify a service plan. If you  change  the plan between versions of your\ntile, the tile generator will attempt to update the plan while preserving\nthe service (thus not causing data loss during upgrade). If the service\ndoes not support plan changes, this will cause the upgrade to fail.  configurable_persistence  is really just a special case of  auto_services ,\nletting the user choose between some standard brokers.", 
            "title": "Automatic Provisioning of Services"
        }, 
        {
            "location": "/tile-generator/#declaring-product-dependencies", 
            "text": "When your product has dependencies on others, you can have Ops Manager\nenforce that dependency by declaring it in your  tile.yml  file as follows:  requires_product_versions:\n- name: p-mysql\n  version: '~  1.7'  If the required product is not present in the PCF installation, Ops Manager\nwill display a message saying your-tile  requires 'p-mysql' version '~  1.7' as a dependency , and will\nrefuse to install your tile until that dependency is satisfied.  When using automatic provisioning of services as described above, it is\noften appropriate to add those products as a dependency. Tile generator can\nnot do this automatically as it can't always determine which product provides\nthe requested service.", 
            "title": "Declaring Product Dependencies"
        }, 
        {
            "location": "/tile-generator/#orgs-and-spaces", 
            "text": "By default, the tile generator will create a single new org and space for any\npackages that install into the Elastic Runtime, using the name of the tile and\nappending  -org  and  -space , respectively. The default memory quota for a\nnewly created or will be 1024 (1G). You can change any of these defaults by\nspecifying the following properties in  tile.yml :  org: test-org\norg_quota: 4096\nspace: test-space", 
            "title": "Orgs and Spaces"
        }, 
        {
            "location": "/tile-generator/#security", 
            "text": "If your cf packages need outbound access (including access to other packages\nwithin the same tile), you will need to apply an appropriate security group.\nThe following option will remove all constraints on outbound traffic:  apply_open_security_group: true", 
            "title": "Security"
        }, 
        {
            "location": "/tile-generator/#stemcells", 
            "text": "The tile generator will default to a recent stemcell supported by Ops Manager.\nIn most cases the default will be fine, as the stemcell is only used to execute\nCF command lines and/or the docker daemon. But if you have specific stemcell\nrequirements, you can override the defaults in your  tile.yml  file by including\na  stemcell-criteria  section and replacing the appopriate values:  stemcell_criteria:\n  os: 'ubunty-trusty'\n  version: '3146.5'     #NOTE: You must quote the version to force the type to be string", 
            "title": "Stemcells"
        }, 
        {
            "location": "/tile-generator/#custom-errands", 
            "text": "Tile generator supplies standard errands to deploy and delete CF type packages. You can\nreplace or augment those errands by specifying errand shell commands in your tile.yml\nfile. For example:  packages:\n- name: meta-buildpack\n  type: buildpack\n  buildpack_order: 0 # Go to head of list\n  path: meta_buildpack.zip\n  deploy: |\n    cp meta_buildpack.zip meta_buildpack-v{{context.version}}.zip\n    existing=`cf buildpacks | grep '^meta_buildpack'`\n    if [ -z  $existing  ]; then\n      cf create-buildpack meta_buildpack meta_buildpack-v{{context.version}}.zip 0\n    else\n      semver=`echo  $existing  | sed 's/.* meta_buildpack-v\\(.*\\)\\.zip/\\1/'`\n      if is_newer  {{context.version}}   $semver ; then\n        cf update-buildpack meta_buildpack -p meta_buildpack-v{{context.version}}.zip\n      else\n        echo  Newer version ($semver) of meta_buildpack is already present \n      fi\n      cf update-buildpack meta_buildpack -i 0\n    fi\n  delete: |\n    # Intentional no-op, as others may have a dependency on this  deploy  and  delete  will completely replace the standard errand commands for the\npackage in which you include them. If you want to keep the standard commands, but\nadd additional commands to execute before or after the standard errand, use pre_deploy ,  post_deploy ,  pre_delete , and/or  post_delete  instead.", 
            "title": "Custom Errands"
        }, 
        {
            "location": "/tile-generator/#versioning", 
            "text": "The tile generator uses  semver versioning . By default,  tile build  will\ngenerate the next patch release. Major and minor releases can be generated\nby explicitly specifying  tile build major  or  tile build minor . Or to\noverride the version number completely, specify a valid semver version on\nthe build command, e.g.  tile build 3.4.5 .  No-op content migration rules are generated for every prior release to the\ncurrent release, so that Ops Manager will allow tile upgrades from any\nversion to any newer version. This depends on the existence of the file tile-history.yml . In a pinch, if you need to be able to upgrade from a\nrandom old version to a new one, you can edit that file, or do:  tile build  old-version \ntile build  new-version   The new tile will then support upgrades from  old-version .", 
            "title": "Versioning"
        }, 
        {
            "location": "/tile-generator/#upgrades", 
            "text": "By default, tile generator produces all code necessary to do a blue/green,\nzero-downtime deployment of all tile components when installing a newer version\nover an older one. For most tile versions this will be all that is needed.  Ops Manager has support for performing upgrade actions, like database migrations,\nduring a tile upgrade, but this capability is not yet exposed through tile\ngenerator.", 
            "title": "Upgrades"
        }, 
        {
            "location": "/tile-generator/#example", 
            "text": "$ tile build\nname: tibco-bwce\nicon: icon.png\nlabel: TIBCO BusinessWorks Container Edition\ndescription: BusinessWorks edition that supports deploying to Cloud Foundry\nversion: 0.0.2\n\nbosh init release\nbosh generate package cf_cli\nbosh generate package bwce_buildpack\nbosh generate job install_bwce_buildpack\nbosh generate job remove_bwce_buildpack\nbosh create release --final --with-tarball --version 0.0.2\n\ntile generate release\ntile generate metadata\ntile generate errand install_bwce_buildpack\ntile generate errand remove_bwce_buildpack\ntile generate content-migrations\n\ncreated tile tibco-bwce-0.0.2.pivotal  This tile includes a single large buildpack, and takes less than 15 seconds\nto build including the CF CLI download and the BOSH release generation.", 
            "title": "Example"
        }, 
        {
            "location": "/tile-generator/#supported-commands", 
            "text": "tile init [ tile-name ]\ntile build [patch|minor|major| version ]", 
            "title": "Supported Commands"
        }, 
        {
            "location": "/tile-generator/#credits", 
            "text": "sparameswaran  supplied most of the actual template content, originally built as part of  cf-platform-eng/bosh-generic-sb-release  frodenas  contributed most of the docker content through  cloudfoundry-community/docker-boshrelease  joshuamckenty  suggested the jinja template approach he employed in  opencontrol", 
            "title": "Credits"
        }, 
        {
            "location": "/pcf-command/", 
            "text": "PCF Utility\n\n\nThe \npcf\n utility provides a command line interface to Pivotal Cloud Foundry for\nthe purpose of deploying and testing tiles. Its primary reason for existence is\nto enable Ops Manager access from CI pipelines, but developers also find it\nconvenient to use this CLI rather than the Ops manager GUI.\n\n\nThe \npcf\n utility also allows you to test your tile's BOSH errands\ndirectly from your CLI, without going through Ops Manager and BOSH. This greatly\nreduces the time it takes to deploy/test each iteration of your software components.\n\n\nAuthentication\n\n\nThe \npcf\n utility looks for a file called \nmetadata\n in the current directory.\nThis file is expected to provide the URL and credentials to connect to\nOps Manager, in the following format:\n\n\n---\nopsmgr:\n    url: https://opsmgr.example.com\n    username: admin\n    password: \nredacted\n\n\n\n\n\nThe reason for this file naming is because this is how Concourse passes\ncredentials of a \"claimed\" PCF pool resource to the CI pipeline scripts.\nFor interactive use, this means that you will have to create a \nmetadata\n\nfile in the directory where you run the \npcf\n command.\n\n\nWe recommend that you do\n \nnot\n \ncreate this file inside your git (or other\nversion control system) repository, as you do not want to accidentally commit\nthese credentials to version control.\n\n\nCommands\n\n\nThe \npcf\n utility implements many different commands. To see available commands:\n\n\n$ pcf --help\nUsage: pcf [OPTIONS] COMMAND [ARGS]...\n\nOptions:\n  --help  Show this message and exit.\n\nCommands:\n  apply-changes\n  cf-info\n  changes\n  configure\n  delete-unused-products\n  import\n  install\n  is-available\n  is-installed\n  logs\n  products\n  settings\n  target\n  test-errand\n  uninstall\n\n\n\n\nChecking Ops Manager Settings\n\n\nTo see which products are currently available and installed in Ops Manager:\n\n\n$ pcf products\n- p-bosh 1.7.0.0 (installed)\n- cf 1.7.0-build.258 (installed)\n- test-tile 0.3.95\n\n\n\n\nTo test if a specific product is available or installed from within a script:\n\n\n$ pcf is-available test-tile \n echo \nProduct test-tile is available\n\n$ pcf is-installed test-tile \n echo \nProduct test-tile is installed\n\n\n\n\n\nYou can retrieve the settings for a specific product (this will give you a \nlot\n of json):\n\n\n$ pcf settings test-tile\n{\n    \nnetwork_reference\n: \n669e213111ab5aa1008a\n,\n    \nguid\n: \ntest-tile-be3e50cf26c530acca6e\n,\n    \njobs\n: [\n        {\n            \ninstance\n: {\n                \nidentifier\n: \ninstances\n\n            },\n            \nidentifier\n: \ncompilation\n,\n            \nguid\n: \ncompilation-066a85d82fbcd936f9d7\n,\n            \ninstallation_name\n: \ncompilation\n,\n            \nvm_credentials\n: {\n                \npassword\n: \nredacted\n,\n                \nsalt\n: \nredacted\n,\n                \nidentity\n: \nvcap\n\n            }\n        },\n        {\n            \nguid\n: \ndeploy-all-b83a7cb7be00ebfd26d6\n,\n            \nvm_credentials\n: {\n    ...\n\n\n\n\n \n\n\nTesting Errands\n\n\nYou can test your tile's BOSH errands directly from your current shell. Deploy\nyour tile's packages using:\n\n\n$ pcf test-errand test-tile-repo deploy-all\n/usr/local/bin/cf version 6.15.0+fa1bfe2-2016-01-13\ncf api https://api.run-04.example.com --skip-ssl-validation\ncf auth system_services \nredacted\n\ncf target -o test-tile-org\ncf update-quota test-tile-org-quota -m 4096m -r 1000 -s 100\ncf update-quota test-tile-org-quota --allow-paid-service-plans\ncf set-quota test-tile-org test-tile-org-quota\ncf target -s test-tile-space\ncf bind-running-security-group all_open\ncf push app1-0.0.2 -n app1 -d cfapps-04.example.com -f sample/release/blobs/app1/manifest.yml --no-start\ncf set-env app1-0.0.2 UAA_HOST https://uaa.run-04.example.com\ncf set-env app1-0.0.2 CC_HOST https://api.run-04.example.com\ncf set-env app1-0.0.2 LOGIN_HOST https://login.run-04.example.com\ncf set-env app1-0.0.2 ROOT $HOME\ncf set-env app1-0.0.2 SCHEME https\ncf set-env app1-0.0.2 VERIFY_SSL True\ncf set-env app1-0.0.2 CF_ORG test-tile-org\ncf set-env app1-0.0.2 CF_SPACE test-tile-space\ncf set-env app1-0.0.2 CF_TARGET https://api.run-04.example.com\ncf set-env app1-0.0.2 SECURITY_USER_NAME admin\n...\n\n\n\n\n\nDelete them using:\n\n\n$ pcf test-errand test-tile-repo delete-all\n/usr/local/bin/cf version 6.15.0+fa1bfe2-2016-01-13\ncf api https://api.run-04.example.com --skip-ssl-validation\ncf auth system_services \nredacted\n\ncf delete -f app3-0.0.2\ncf delete-buildpack -f noop_buildpack\ncf purge-service-offering -f service-broker2-service\ncf delete-service-broker -f service-broker2\ncf delete -f service-broker2-0.0.2\ncf delete -f app2-0.0.2\ncf purge-service-offering -f service-broker1-service\ncf delete-service-broker -f service-broker1\ncf delete -f service-broker1-0.0.2\ncf delete -f app1-0.0.2\ncf delete-space -f test-tile-space\ncf delete-org -f test-tile-org\ncf delete-quota -f test-tile-org-quota\n\n\n\n\n\nThis \nonly\n reliably works for the above two errands generated by the tile\ngenerator. If your tile includes any packages that are not deployed into them\nElastic Runtime, such as docker-bosh packages, those will not be deployed when\nusing this method.\n\n\nDeploying Tiles\n\n\nOnce your software works and correctly deploys using \ntest-errand\n, you can go\nthrough the real Ops Manager deployment process from the CLI, as you would\nnormally do through the Ops Manager GUI.\n\n\nImport your .pivotal file into Ops Manager:\n\n\n$ pcf import sample/product/test-tile-0.0.2.pivotal\n\n\n\n\nInstall the uploaded version of your product:\n\n\n$ pcf install test-tile 0.0.2\n\n\n\n\nWhere you would normally configure the tile settings in the GUI, the \nconfigure\n\ncommand lets you pass in any user-specified properties as a .yml file. This command\nalso sets the stemcell for the tile to the same one used by your Elastic Runtime,\nto avoid the need to upload a tile-specific stemcell.\n\n\n$ pcf configure test-tile sample/missing-properties.yml\n- Using stemcell bosh-vsphere-esxi-ubuntu-trusty-go_agent version 3215\n\n\n\n\nThe property file looks like this:\n\n\n---\ncustomer_name: Jimmy's Johnnys\nstreet_address: Cartaway Alley\ncity: New Jersey\ncountry: US\nusername: SpongeBob\npassword: { 'secret': SquarePants }\napp2:\n  persistence_store_type: none\n# In PCF 1.8+, BOSH-job-specific configuration is supported:\njobs:\n  a_job:\n    # Job resource configuration:\n    resource_config:\n      persistent_disk:\n        size_mb: \n10240\n\n    # Job-specific property configuration:\n    job_property: property_value\n\n\n\n\nNote\n the special handling of the \nsecret\n type property. Specifying a simple\nstring value for a field of this type will result in a \n500 System Error\n being\nreturned from \npcf configure\n.\n\n\nTo see what changes are ready to be applied:\n\n\n$ pcf changes\ninstall: test-tile-207b165fcb7dc8b2597b\ndelete:  \n\n\n\n\nTo apply these changes:\n\n\n$ pcf apply-changes\n  ===== 2016-04-21 18:45:05 UTC Running \nbosh-init deploy /var/tempest/workspaces/default/deployments/bosh.yml\n\n  Deployment manifest: '/var/tempest/workspaces/default/deployments/bosh.yml'\n  Deployment state: '/var/tempest/workspaces/default/deployments/bosh-state.json'\n\n  Started validating\n    Validating release 'bosh'... Finished (00:00:08)\n    Validating release 'bosh-vsphere-cpi'... Finished (00:00:00)\n    Validating release 'uaa'... Finished (00:00:06)\n    Validating cpi release... Finished (00:00:00)\n    Validating deployment manifest... Finished (00:00:00)\n\n\n\n\npcf apply-changes\n automatically tails the logs for the installation process\nit started. If this gets aborted for any reason, you can always tail the logs\nof the most recent installation:\n\n\n$ pcf logs\n\n\n\n\nRemoving Tiles\n\n\nTo uninstall a tile:\n\n\n$ pcf uninstall test-tile\n\n\n\n\nIf you accumulate a lot of uninstalled tiles or old versions, you can clean\nup Ops Manager's available products (and disk space):\n\n\n$ pcf delete-unused-products\n\n\n\n\nAccessing Elastic Runtime\n\n\nTo see details about the Elastic Runtime of your PCF environment:\n\n\n$ pcf cf-info\n- admin_password: \nredacted\n\n- admin_username: admin\n- apps_domain: cfapps-04.example.com\n- system_domain: run-04.example.com\n- system_services_password: \nredacted\n\n- system_services_username: system_services\n\n\n\n\nTo target your \ncf\n command line at this PCF environment:\n\n\n$ pcf target\nSetting api endpoint to api.example.com...\nOK\n\nAPI endpoint:   https://api.example.com (API version: 2.52.0)   \nUser:           admin   \nOrg:            my-org\nSpace:          my-space\nAPI endpoint: https://api.example.com\nAuthenticating...\nOK\n\n...", 
            "title": "PCF Command"
        }, 
        {
            "location": "/pcf-command/#pcf-utility", 
            "text": "The  pcf  utility provides a command line interface to Pivotal Cloud Foundry for\nthe purpose of deploying and testing tiles. Its primary reason for existence is\nto enable Ops Manager access from CI pipelines, but developers also find it\nconvenient to use this CLI rather than the Ops manager GUI.  The  pcf  utility also allows you to test your tile's BOSH errands\ndirectly from your CLI, without going through Ops Manager and BOSH. This greatly\nreduces the time it takes to deploy/test each iteration of your software components.", 
            "title": "PCF Utility"
        }, 
        {
            "location": "/pcf-command/#authentication", 
            "text": "The  pcf  utility looks for a file called  metadata  in the current directory.\nThis file is expected to provide the URL and credentials to connect to\nOps Manager, in the following format:  ---\nopsmgr:\n    url: https://opsmgr.example.com\n    username: admin\n    password:  redacted   The reason for this file naming is because this is how Concourse passes\ncredentials of a \"claimed\" PCF pool resource to the CI pipeline scripts.\nFor interactive use, this means that you will have to create a  metadata \nfile in the directory where you run the  pcf  command.  We recommend that you do   not   create this file inside your git (or other\nversion control system) repository, as you do not want to accidentally commit\nthese credentials to version control.", 
            "title": "Authentication"
        }, 
        {
            "location": "/pcf-command/#commands", 
            "text": "The  pcf  utility implements many different commands. To see available commands:  $ pcf --help\nUsage: pcf [OPTIONS] COMMAND [ARGS]...\n\nOptions:\n  --help  Show this message and exit.\n\nCommands:\n  apply-changes\n  cf-info\n  changes\n  configure\n  delete-unused-products\n  import\n  install\n  is-available\n  is-installed\n  logs\n  products\n  settings\n  target\n  test-errand\n  uninstall", 
            "title": "Commands"
        }, 
        {
            "location": "/pcf-command/#checking-ops-manager-settings", 
            "text": "To see which products are currently available and installed in Ops Manager:  $ pcf products\n- p-bosh 1.7.0.0 (installed)\n- cf 1.7.0-build.258 (installed)\n- test-tile 0.3.95  To test if a specific product is available or installed from within a script:  $ pcf is-available test-tile   echo  Product test-tile is available \n$ pcf is-installed test-tile   echo  Product test-tile is installed   You can retrieve the settings for a specific product (this will give you a  lot  of json):  $ pcf settings test-tile\n{\n     network_reference :  669e213111ab5aa1008a ,\n     guid :  test-tile-be3e50cf26c530acca6e ,\n     jobs : [\n        {\n             instance : {\n                 identifier :  instances \n            },\n             identifier :  compilation ,\n             guid :  compilation-066a85d82fbcd936f9d7 ,\n             installation_name :  compilation ,\n             vm_credentials : {\n                 password :  redacted ,\n                 salt :  redacted ,\n                 identity :  vcap \n            }\n        },\n        {\n             guid :  deploy-all-b83a7cb7be00ebfd26d6 ,\n             vm_credentials : {\n    ...", 
            "title": "Checking Ops Manager Settings"
        }, 
        {
            "location": "/pcf-command/#testing-errands", 
            "text": "You can test your tile's BOSH errands directly from your current shell. Deploy\nyour tile's packages using:  $ pcf test-errand test-tile-repo deploy-all\n/usr/local/bin/cf version 6.15.0+fa1bfe2-2016-01-13\ncf api https://api.run-04.example.com --skip-ssl-validation\ncf auth system_services  redacted \ncf target -o test-tile-org\ncf update-quota test-tile-org-quota -m 4096m -r 1000 -s 100\ncf update-quota test-tile-org-quota --allow-paid-service-plans\ncf set-quota test-tile-org test-tile-org-quota\ncf target -s test-tile-space\ncf bind-running-security-group all_open\ncf push app1-0.0.2 -n app1 -d cfapps-04.example.com -f sample/release/blobs/app1/manifest.yml --no-start\ncf set-env app1-0.0.2 UAA_HOST https://uaa.run-04.example.com\ncf set-env app1-0.0.2 CC_HOST https://api.run-04.example.com\ncf set-env app1-0.0.2 LOGIN_HOST https://login.run-04.example.com\ncf set-env app1-0.0.2 ROOT $HOME\ncf set-env app1-0.0.2 SCHEME https\ncf set-env app1-0.0.2 VERIFY_SSL True\ncf set-env app1-0.0.2 CF_ORG test-tile-org\ncf set-env app1-0.0.2 CF_SPACE test-tile-space\ncf set-env app1-0.0.2 CF_TARGET https://api.run-04.example.com\ncf set-env app1-0.0.2 SECURITY_USER_NAME admin\n...  Delete them using:  $ pcf test-errand test-tile-repo delete-all\n/usr/local/bin/cf version 6.15.0+fa1bfe2-2016-01-13\ncf api https://api.run-04.example.com --skip-ssl-validation\ncf auth system_services  redacted \ncf delete -f app3-0.0.2\ncf delete-buildpack -f noop_buildpack\ncf purge-service-offering -f service-broker2-service\ncf delete-service-broker -f service-broker2\ncf delete -f service-broker2-0.0.2\ncf delete -f app2-0.0.2\ncf purge-service-offering -f service-broker1-service\ncf delete-service-broker -f service-broker1\ncf delete -f service-broker1-0.0.2\ncf delete -f app1-0.0.2\ncf delete-space -f test-tile-space\ncf delete-org -f test-tile-org\ncf delete-quota -f test-tile-org-quota  This  only  reliably works for the above two errands generated by the tile\ngenerator. If your tile includes any packages that are not deployed into them\nElastic Runtime, such as docker-bosh packages, those will not be deployed when\nusing this method.", 
            "title": "Testing Errands"
        }, 
        {
            "location": "/pcf-command/#deploying-tiles", 
            "text": "Once your software works and correctly deploys using  test-errand , you can go\nthrough the real Ops Manager deployment process from the CLI, as you would\nnormally do through the Ops Manager GUI.  Import your .pivotal file into Ops Manager:  $ pcf import sample/product/test-tile-0.0.2.pivotal  Install the uploaded version of your product:  $ pcf install test-tile 0.0.2  Where you would normally configure the tile settings in the GUI, the  configure \ncommand lets you pass in any user-specified properties as a .yml file. This command\nalso sets the stemcell for the tile to the same one used by your Elastic Runtime,\nto avoid the need to upload a tile-specific stemcell.  $ pcf configure test-tile sample/missing-properties.yml\n- Using stemcell bosh-vsphere-esxi-ubuntu-trusty-go_agent version 3215  The property file looks like this:  ---\ncustomer_name: Jimmy's Johnnys\nstreet_address: Cartaway Alley\ncity: New Jersey\ncountry: US\nusername: SpongeBob\npassword: { 'secret': SquarePants }\napp2:\n  persistence_store_type: none\n# In PCF 1.8+, BOSH-job-specific configuration is supported:\njobs:\n  a_job:\n    # Job resource configuration:\n    resource_config:\n      persistent_disk:\n        size_mb:  10240 \n    # Job-specific property configuration:\n    job_property: property_value  Note  the special handling of the  secret  type property. Specifying a simple\nstring value for a field of this type will result in a  500 System Error  being\nreturned from  pcf configure .  To see what changes are ready to be applied:  $ pcf changes\ninstall: test-tile-207b165fcb7dc8b2597b\ndelete:    To apply these changes:  $ pcf apply-changes\n  ===== 2016-04-21 18:45:05 UTC Running  bosh-init deploy /var/tempest/workspaces/default/deployments/bosh.yml \n  Deployment manifest: '/var/tempest/workspaces/default/deployments/bosh.yml'\n  Deployment state: '/var/tempest/workspaces/default/deployments/bosh-state.json'\n\n  Started validating\n    Validating release 'bosh'... Finished (00:00:08)\n    Validating release 'bosh-vsphere-cpi'... Finished (00:00:00)\n    Validating release 'uaa'... Finished (00:00:06)\n    Validating cpi release... Finished (00:00:00)\n    Validating deployment manifest... Finished (00:00:00)  pcf apply-changes  automatically tails the logs for the installation process\nit started. If this gets aborted for any reason, you can always tail the logs\nof the most recent installation:  $ pcf logs", 
            "title": "Deploying Tiles"
        }, 
        {
            "location": "/pcf-command/#removing-tiles", 
            "text": "To uninstall a tile:  $ pcf uninstall test-tile  If you accumulate a lot of uninstalled tiles or old versions, you can clean\nup Ops Manager's available products (and disk space):  $ pcf delete-unused-products", 
            "title": "Removing Tiles"
        }, 
        {
            "location": "/pcf-command/#accessing-elastic-runtime", 
            "text": "To see details about the Elastic Runtime of your PCF environment:  $ pcf cf-info\n- admin_password:  redacted \n- admin_username: admin\n- apps_domain: cfapps-04.example.com\n- system_domain: run-04.example.com\n- system_services_password:  redacted \n- system_services_username: system_services  To target your  cf  command line at this PCF environment:  $ pcf target\nSetting api endpoint to api.example.com...\nOK\n\nAPI endpoint:   https://api.example.com (API version: 2.52.0)   \nUser:           admin   \nOrg:            my-org\nSpace:          my-space\nAPI endpoint: https://api.example.com\nAuthenticating...\nOK\n\n...", 
            "title": "Accessing Elastic Runtime"
        }, 
        {
            "location": "/concourse/", 
            "text": "Concourse Continuous Integration\n\n\nCloud Foundry is a fast moving platform as we are constantly extending and\nenhancing it. When you integrate your software with Cloud Foundry, it is\nimportant to make sure that your integration continues to work with every\nnew release of the platform. A great way to ensure that is to set up a CI\npipeline for your tile against a PCF deployment that is constantly updated\nwith the latest Alpha release of the platform.\n\n\nOur tool of choice for setting up CI is \nconcourse\n.\nWhile you are of course free to use whetever system you are familiar with,\nour tools and documentation are built to make concourse CI as easy as\npossible.\n\n\n \n\n\nSetting up a Concourse Server\n\n\nYou will need a concourse server to host your pipeline. If you partner with\nus, we have servers that can host your pipeline, and S3 storage that can be\nused to transfer artifacts to and from your servers. If you choose to set\nup your own, instructions can be found here:\n\n\n\n\nSetting up concourse\n\n\n\n\n \n\n\nCreating a Concourse Pipeline for your Tile\n\n\nA typical CI pipeline for a tile consists of the following jobs:\n\n\n\n\nBuild the tile\n\n\nDeploy it to PCF\n\n\nRun a set of deployment tests to verify that it deployed and works correctly\n\n\nRemove it from PCF\n\n\n\n\nYou describe this pipeline in a pipeline.yml file that is then uploaded to the\nconcourse server. \nTile Generator\n contains a sample\npipeline that you can clone for your own tile. \n\n\nWe have provided a \ndocker image\n to help you \nautomate your tile creation tasks via concourse. To make use of this image, you will want to do the following:\n\n\n\n\nDeclare a concourse resource for the tile source in your pipeline.yml file:\n\n\n\n\nyml\n  - name: tile-source\n    type: git\n    source:\n      branch: master\n      uri: https://github.com/your-tile-project-repo\n\n1. Declare a resource to store the artifacts of your build process (for example, an aws s3 bucket) in your pipeline.yml file:\n\n\nyml\n  - name: tile-build\n    type: s3\n    source:\n      access_key_id: your-aws-key-id-don't-check-this-in!\n      bucket: your-aws-bucket-name\n      regexp: .*-(?P\nversion\n.*)\\.jar\n      secret_access_key: your-aws-access-key-don't-check-this-in!\n\n1. Declare a resource to store your tile in your pipeline.yml file:\n\n\nyml\n  - name: tile\n    type: s3\n    source:\n      access_key_id: your-aws-key-id-don't-check-this-in!\n      bucket: your-aws-bucket-name\n      regexp: .*-(?P\nversion\n.*)\\.pivotal\n      secret_access_key: your-aws-access-key-don't-check-this-in!\n\n1. Declare a resource to store a tile-history.yml file. This file is needed by the tile-generator process:\n\n\nyml\n  - name: tile-history\n    type: s3\n    source:\n      access_key_id: your-aws-key-id-don't-check-this-in!\n      bucket: your-aws-bucket-name\n      regexp: tile-history-(?P\nversion\n.*)\\.yml\n      secret_access_key: your-aws-access-key-don't-check-this-in!\n\n1. (Optional) consider managing the versioning of your project via \nsemver\n. If you decide to do this, add something like the following to your pipeline.yml file:\n\n\nyml\n  - name: version\n    type: semver\n    source:\n      bucket: your-aws-bucket-name\n      key: current-version\n      access_key_id: your-aws-key-id-don't-check-this-in!\n      secret_access_key: your-aws-access-key-don't-check-this-in!\n      initial_version: 1.0.0\n\n1. add a job such as the following, to your pipeline:\n\n\nyml\n  - name: build-tile\n    serial_groups: [version]\n    plan:\n    - aggregate:\n      - get: tile-source\n      - get: tile-build\n      - get: version\n      - get: tile-history\n    - task: build-tile\n      file: tile-source/ci/build-tile/task.yml\n    - put: tile-history\n      params: {file: tile-history-new/*.yml}\n    - put: tile\n      params: {file: broker-tile/*.pivotal}\n\n1. define the tile build task via a task.yml file (per the above job configuration, this file would be added to the ci/build-tile directory in your source repository):\n\n\n```yml\n  platform: linux\n\n\nimage: docker:///cfplatformeng/tile-generator\n\n\ninputs:\n  - name: tile-source\n  - name: tile-build\n  - name: version\n  - name: tile-history\n\n\noutputs:\n  - name: tile\n  - name: tile-history-new\n\n\nrun:\n    path: tile-repo/ci/build-tile/task.sh\n```\n1. create a task.sh script to build the tile (per the above job configuration, this file would be added to the ci/build-tile directory in your source repository):\n\n\n```sh\n  #!/bin/sh -ex\n\n\ncd tile-repo\n\n\ncp ../../tile-build/* the-place-in-tile.yml-where-the-build-goes\n\n\nver=\nmore ../version/number\n\n  tile build ${ver}\n\n\nfile=\nls product/*.pivotal\n\n  filename=$(basename \"${file}\")\n  filename=\"${filename%-*}\"\n\n\ncp ${file} ../tile/${filename}-${ver}.pivotal\n  cp tile-history.yml ../tile-history-new/tile-history-${ver}.yml\n  ``` \n1. string this job together with the other jobs in your pipeline (probably after a successful tile-build). The job will then build your tile and place it in your s3 bucket along with an updated tile-history file.\n\n\n \n\n\nSetting up PCF for your CI Pipeline\n\n\nPivotal partners who have us host their pipeline have access to a pool of PCF\ninstances that are managed by us and are regularly updated with the latest\n(pre-)release versions of PCF. If you set up your own concourse server, you\nwill have to target your pipeline at a \nPCF instance you have setup\n.\n\n\nConcourse has a resource type to manage a pool of resources that are shared\nbetween pipelines, which is what we use to serialize PCF access between the\npartner pipelines that run on our concourse server.", 
            "title": "Concourse"
        }, 
        {
            "location": "/concourse/#concourse-continuous-integration", 
            "text": "Cloud Foundry is a fast moving platform as we are constantly extending and\nenhancing it. When you integrate your software with Cloud Foundry, it is\nimportant to make sure that your integration continues to work with every\nnew release of the platform. A great way to ensure that is to set up a CI\npipeline for your tile against a PCF deployment that is constantly updated\nwith the latest Alpha release of the platform.  Our tool of choice for setting up CI is  concourse .\nWhile you are of course free to use whetever system you are familiar with,\nour tools and documentation are built to make concourse CI as easy as\npossible.", 
            "title": "Concourse Continuous Integration"
        }, 
        {
            "location": "/concourse/#setting-up-a-concourse-server", 
            "text": "You will need a concourse server to host your pipeline. If you partner with\nus, we have servers that can host your pipeline, and S3 storage that can be\nused to transfer artifacts to and from your servers. If you choose to set\nup your own, instructions can be found here:   Setting up concourse", 
            "title": "Setting up a Concourse Server"
        }, 
        {
            "location": "/concourse/#creating-a-concourse-pipeline-for-your-tile", 
            "text": "A typical CI pipeline for a tile consists of the following jobs:   Build the tile  Deploy it to PCF  Run a set of deployment tests to verify that it deployed and works correctly  Remove it from PCF   You describe this pipeline in a pipeline.yml file that is then uploaded to the\nconcourse server.  Tile Generator  contains a sample\npipeline that you can clone for your own tile.   We have provided a  docker image  to help you \nautomate your tile creation tasks via concourse. To make use of this image, you will want to do the following:   Declare a concourse resource for the tile source in your pipeline.yml file:   yml\n  - name: tile-source\n    type: git\n    source:\n      branch: master\n      uri: https://github.com/your-tile-project-repo \n1. Declare a resource to store the artifacts of your build process (for example, an aws s3 bucket) in your pipeline.yml file:  yml\n  - name: tile-build\n    type: s3\n    source:\n      access_key_id: your-aws-key-id-don't-check-this-in!\n      bucket: your-aws-bucket-name\n      regexp: .*-(?P version .*)\\.jar\n      secret_access_key: your-aws-access-key-don't-check-this-in! \n1. Declare a resource to store your tile in your pipeline.yml file:  yml\n  - name: tile\n    type: s3\n    source:\n      access_key_id: your-aws-key-id-don't-check-this-in!\n      bucket: your-aws-bucket-name\n      regexp: .*-(?P version .*)\\.pivotal\n      secret_access_key: your-aws-access-key-don't-check-this-in! \n1. Declare a resource to store a tile-history.yml file. This file is needed by the tile-generator process:  yml\n  - name: tile-history\n    type: s3\n    source:\n      access_key_id: your-aws-key-id-don't-check-this-in!\n      bucket: your-aws-bucket-name\n      regexp: tile-history-(?P version .*)\\.yml\n      secret_access_key: your-aws-access-key-don't-check-this-in! \n1. (Optional) consider managing the versioning of your project via  semver . If you decide to do this, add something like the following to your pipeline.yml file:  yml\n  - name: version\n    type: semver\n    source:\n      bucket: your-aws-bucket-name\n      key: current-version\n      access_key_id: your-aws-key-id-don't-check-this-in!\n      secret_access_key: your-aws-access-key-don't-check-this-in!\n      initial_version: 1.0.0 \n1. add a job such as the following, to your pipeline:  yml\n  - name: build-tile\n    serial_groups: [version]\n    plan:\n    - aggregate:\n      - get: tile-source\n      - get: tile-build\n      - get: version\n      - get: tile-history\n    - task: build-tile\n      file: tile-source/ci/build-tile/task.yml\n    - put: tile-history\n      params: {file: tile-history-new/*.yml}\n    - put: tile\n      params: {file: broker-tile/*.pivotal} \n1. define the tile build task via a task.yml file (per the above job configuration, this file would be added to the ci/build-tile directory in your source repository):  ```yml\n  platform: linux  image: docker:///cfplatformeng/tile-generator  inputs:\n  - name: tile-source\n  - name: tile-build\n  - name: version\n  - name: tile-history  outputs:\n  - name: tile\n  - name: tile-history-new  run:\n    path: tile-repo/ci/build-tile/task.sh\n```\n1. create a task.sh script to build the tile (per the above job configuration, this file would be added to the ci/build-tile directory in your source repository):  ```sh\n  #!/bin/sh -ex  cd tile-repo  cp ../../tile-build/* the-place-in-tile.yml-where-the-build-goes  ver= more ../version/number \n  tile build ${ver}  file= ls product/*.pivotal \n  filename=$(basename \"${file}\")\n  filename=\"${filename%-*}\"  cp ${file} ../tile/${filename}-${ver}.pivotal\n  cp tile-history.yml ../tile-history-new/tile-history-${ver}.yml\n  ``` \n1. string this job together with the other jobs in your pipeline (probably after a successful tile-build). The job will then build your tile and place it in your s3 bucket along with an updated tile-history file.", 
            "title": "Creating a Concourse Pipeline for your Tile"
        }, 
        {
            "location": "/concourse/#setting-up-pcf-for-your-ci-pipeline", 
            "text": "Pivotal partners who have us host their pipeline have access to a pool of PCF\ninstances that are managed by us and are regularly updated with the latest\n(pre-)release versions of PCF. If you set up your own concourse server, you\nwill have to target your pipeline at a  PCF instance you have setup .  Concourse has a resource type to manage a pool of resources that are shared\nbetween pipelines, which is what we use to serialize PCF access between the\npartner pipelines that run on our concourse server.", 
            "title": "Setting up PCF for your CI Pipeline"
        }, 
        {
            "location": "/service-brokers/", 
            "text": "How to Build a Service Broker\n\n\n\n\nCustom Services\n\n\nService Broker API\n\n\nRoute Services\n\n\n\n\nExample Service Brokers\n\n\n\n\nExample Service Brokers\n\n\nExample Route Services", 
            "title": "Service Brokers"
        }, 
        {
            "location": "/service-brokers/#how-to-build-a-service-broker", 
            "text": "Custom Services  Service Broker API  Route Services", 
            "title": "How to Build a Service Broker"
        }, 
        {
            "location": "/service-brokers/#example-service-brokers", 
            "text": "Example Service Brokers  Example Route Services", 
            "title": "Example Service Brokers"
        }, 
        {
            "location": "/managed-services/", 
            "text": "How to Build a Managed Service\n\n\nA managed service is a service deployed on Cloud Foundry infrastructure\n(in other words, the same IaaS that your particular Cloud Foundry instance\nis deployed on) by the same orchestration tool, \nbosh\n.\nOffering your software as a managed service means that your PCF customers\nwill not have to learn different ways to deploy, manage, and monitor\ndifferent components of their application platform.\n\n\nFor bosh to manage your service, the major components needed are:\n\n\n\n\nPackages\n that can be installed on PCF stemcells to create virtual machine images\n\n\nJobs\n that describe how to install, run, and remove your software\n\n\nA \nMonitor\n script, that describes how to monitor the health of your\nservice components and stop or restart them\n\n\n\n\nBOSH overview\n\n\n\n\nBOSH Documentation\n\n\nBOSH Problem Statement\n\n\nBOSH Basic Workflow\n\n\n\n\nCreating a BOSH Release\n\n\n\n\nCreating a Release\n\n\nDefining your Jobs\n\n\nDefining your VMs\n\n\nMonitoring the Health of your Service\n\n\n\n\nShortcut - Start with Docker images\n\n\nIf you have already packaged your service as docker images, you can emulate\na managed service deployment using the \nTile Generator\n's\nsupport for docker-bosh packages. This feature lets you deploy pre-existing\ndocker images into bash managed virtual machines on the PCF infrastructure.\n\n\nWhile this is a great, easy way to deploy your service on PCF, we don't\nrecommend this as a long-term, production-ready solution. There is really no\nbenefit of running your service in containers on the VMs, and it does have\na number of operational (\"day 2\") drawbacks:\n\n\n\n\nYou introduce more software (docker) which needs to be kept up-to-date, and\nhas the potential for bugs, downtime, and security vulnerabilities.\n\n\nYou can no longer take advantage of the patching capabilities of PCF for\nstemcells and application dependencies, like frameworks and libraries. Instead,\nyou become directly responsible for managing all software that is in the docker\nimages you deploy.", 
            "title": "Managed Services"
        }, 
        {
            "location": "/managed-services/#how-to-build-a-managed-service", 
            "text": "A managed service is a service deployed on Cloud Foundry infrastructure\n(in other words, the same IaaS that your particular Cloud Foundry instance\nis deployed on) by the same orchestration tool,  bosh .\nOffering your software as a managed service means that your PCF customers\nwill not have to learn different ways to deploy, manage, and monitor\ndifferent components of their application platform.  For bosh to manage your service, the major components needed are:   Packages  that can be installed on PCF stemcells to create virtual machine images  Jobs  that describe how to install, run, and remove your software  A  Monitor  script, that describes how to monitor the health of your\nservice components and stop or restart them", 
            "title": "How to Build a Managed Service"
        }, 
        {
            "location": "/managed-services/#bosh-overview", 
            "text": "BOSH Documentation  BOSH Problem Statement  BOSH Basic Workflow", 
            "title": "BOSH overview"
        }, 
        {
            "location": "/managed-services/#creating-a-bosh-release", 
            "text": "Creating a Release  Defining your Jobs  Defining your VMs  Monitoring the Health of your Service", 
            "title": "Creating a BOSH Release"
        }, 
        {
            "location": "/managed-services/#shortcut-start-with-docker-images", 
            "text": "If you have already packaged your service as docker images, you can emulate\na managed service deployment using the  Tile Generator 's\nsupport for docker-bosh packages. This feature lets you deploy pre-existing\ndocker images into bash managed virtual machines on the PCF infrastructure.  While this is a great, easy way to deploy your service on PCF, we don't\nrecommend this as a long-term, production-ready solution. There is really no\nbenefit of running your service in containers on the VMs, and it does have\na number of operational (\"day 2\") drawbacks:   You introduce more software (docker) which needs to be kept up-to-date, and\nhas the potential for bugs, downtime, and security vulnerabilities.  You can no longer take advantage of the patching capabilities of PCF for\nstemcells and application dependencies, like frameworks and libraries. Instead,\nyou become directly responsible for managing all software that is in the docker\nimages you deploy.", 
            "title": "Shortcut - Start with Docker images"
        }, 
        {
            "location": "/dynamic-services/", 
            "text": "How to Build a Dynamic Service\n\n\nDynamic, or on-demand, service capabilities are coming in bosh 2.0 and\nPCF 1.8. You can get access to these features now if you partner with\nPivotal. Otherwise, check back frequently for the first public\nrelease of these capabilities.", 
            "title": "Dynamic Services"
        }, 
        {
            "location": "/dynamic-services/#how-to-build-a-dynamic-service", 
            "text": "Dynamic, or on-demand, service capabilities are coming in bosh 2.0 and\nPCF 1.8. You can get access to these features now if you partner with\nPivotal. Otherwise, check back frequently for the first public\nrelease of these capabilities.", 
            "title": "How to Build a Dynamic Service"
        }, 
        {
            "location": "/buildpacks/", 
            "text": "How to Create a Buildpack\n\n\n\n\nCreating a custom buildpack\n\n\n\n\nOfficial buildpacks\n\n\n\n\nJava buildpack\n (by far the most compicated!)\n\n\nGo buildpack\n\n\nRuby buildpack\n\n\nNode.js buildpack\n\n\nPython buildpack\n\n\nPHP buildpack\n\n\nStatic file buildpack\n (for static web content)\n\n\nBinary buildpack\n\n\n\n\nOther buildpacks\n\n\n\n\nMeta-buildpack\n\n\nSpring Config decorator buildpack", 
            "title": "Buildpacks"
        }, 
        {
            "location": "/buildpacks/#how-to-create-a-buildpack", 
            "text": "Creating a custom buildpack", 
            "title": "How to Create a Buildpack"
        }, 
        {
            "location": "/buildpacks/#official-buildpacks", 
            "text": "Java buildpack  (by far the most compicated!)  Go buildpack  Ruby buildpack  Node.js buildpack  Python buildpack  PHP buildpack  Static file buildpack  (for static web content)  Binary buildpack", 
            "title": "Official buildpacks"
        }, 
        {
            "location": "/buildpacks/#other-buildpacks", 
            "text": "Meta-buildpack  Spring Config decorator buildpack", 
            "title": "Other buildpacks"
        }, 
        {
            "location": "/embedded-agents/", 
            "text": "How to Build an Embedded Agent\n\n\nSome integrations depend on the ability to inject code into the application container.\nExamples of this include:\n\n\n\n\nApplication Performance Monitoring (APM) agents\n\n\nContainer-embedded API gateways\n\n\nClient-side routers\n\n\n\n\nWe refer to these injected components as \"container-embedded agents\".\n\nBuildpacks\n provide a mechanism to inject components into the application\ncontainer image, and the \n.profile.d\n directory provides a way to start agents before or\nalongside the customer application.\n\n\n\n\nAgent Injection with the meta-buildpack\n\n\nUsing .profile.d", 
            "title": "Embedded Agents"
        }, 
        {
            "location": "/embedded-agents/#how-to-build-an-embedded-agent", 
            "text": "Some integrations depend on the ability to inject code into the application container.\nExamples of this include:   Application Performance Monitoring (APM) agents  Container-embedded API gateways  Client-side routers   We refer to these injected components as \"container-embedded agents\". Buildpacks  provide a mechanism to inject components into the application\ncontainer image, and the  .profile.d  directory provides a way to start agents before or\nalongside the customer application.   Agent Injection with the meta-buildpack  Using .profile.d", 
            "title": "How to Build an Embedded Agent"
        }, 
        {
            "location": "/nozzles/", 
            "text": "How to Build a Nozzle\n\n\nOverview\n\n\nCloud Foundry's logging system, Loggregator,\nhas a feature called firehose. The firehose includes the combined stream of logs \nand metrics from every apps as well as\nthe Cloud Foundry platform itself. Building a nozzle could be a solution for\n\n\n\n\nDraining metrics to an external dashboard product for sytem operators\n\n\nSending every http request's details into a search tool\n\n\nDraining all application logs to an external system \n\n\nThinking a little differently, \nthis video shows auto-scaling an app based on firehose metrics\n\n\n\n\nFirehose-to-syslog is a real world, production example\n\nof a nozzle.\n\n\nBuilding\n\n\nDeveloping a nozzle should be done in Go, as this allows leveraging the\n\nNOAA library\n.\nNOAA does the heavy lifting of establishing\nan authenticated websocket connection to the logging system\nas well as de-serializing the protocol buffers.\n\n\nDraining the logs consists of:\n\n\n\n\nAuthenticating\n\n\nEstablishing a connection to the logging system\n\n\nForwarding events on to their ultimate destination\n\n\n\n\nAuthenticate by fetching a token from \nuaa\n\nwith a client having the \ndoppler.firehose\n scope:\n\n\n    uaaClient, err := uaago.NewClient(uaaUrl)\n    if err != nil {\n        panic(err)\n    }\n\n    token, err := uaaClient.GetAuthToken(username, password, skipSSL)\n    if err != nil {\n        panic(err)\n    }\n\n\n\n\nUsing the token, create a consumer and connect to the Firehose with a subscription id.\nThe id is important, since the firehose looks for connections having the same id and only\nsends an event to one of those connections. This is how a nozzle developer can prevent\nmessage loss during upgrades an other deployments: run at least two instances.\n\n\n    consumer := consumer.New(config.TrafficControllerURL, \ntls.Config{\n        InsecureSkipVerify: config.SkipSSL,\n    }, nil)\n    events, errors := consumer.Firehose(firehoseSubscriptionID, token)\n\n\n\n\nFirehose\n will give back two channels: one for events and a second for errors.\n\n\nThe events channel receives six different types of events.\n\n\n\n\nValueMetric: some platform metric at a point in time, emitted by platform components (for example, how many 2xx responses the router has sent out)\n\n\nCounterEvent: an incrementing counter, emitted by platform components (for example, a diego cells remaining memory capacity)\n\n\nError: an error\n\n\nHttpStartStop: http request details, including both application and platform requests\n\n\nLogMessage:  a log message for an individual app\n\n\nContainerMetric: application container information (for example, memory used)\n\n\n\n\nFor the full details on events, check the\n\ndropsonde protocol\n.\n\n\nThe above events show how this data targets two different personae:\nplatform operators and application developers. Keep this in mind when designing an integration.\n\n\nHaving \ndoppler.firehose\n scope gets a nozzle data for \nevery\n application as well as the platform. \nAny filtering based on the event payload is the nozzle implementor's responsibility.\nAn advanced integration could do something like combine a\n\nservice broker\n with a nozzle to:\n\n\n\n\nLet application developers opt-in to logging (implementing filtering in the nozzle)\n\n\nEstablish \nSSO\n exchange for authentication such that developers only can access logs for their space's apps\n\n\n\n\nFor a full working example, see \nfirehose-nozzle\n.\n\n\nDeployment\n\n\nOnce you've build a nozzle, there are a couple options for deployment\n\n\nAs a Managed Service\n\n\nVisit \nmanaged service\n\nfor more details on what it means to be a managed service.\n\n\nSee also this\n\nexample nozzle BOSH release\n.\n\n\nAs an App\n\n\nYou could also deploy the nozzle on the elastic runtime itself.\nVisit the Tile Generator's\n\nsection on pushed appliactions\n\nfor more details.\n\n\nOpen Source Nozzles\n\n\nThere are several open source examples you could use\nas a reference for building your nozzle\n\n\nfirehose-nozzle\n\n\n\n\nExample that simply writes to standard out\n\n\nUseful starting point: scaffolding, tests, etc are in place\n\n\n\n\nexample-nozzle\n\n\n\n\nA single file implementation with no tests: as minimal as things can get\n\n\n\n\ngcp-tools-release\n\n\n\n\nIn addition to Nozzle data, it drains component syslogs and health data\n\n\nShows how to do a bosh-addon (for additional data outside a nozzle)\n\n\nNozzle is managed via bosh\n\n\nRaw logs and metrics data take different paths in the source\n\n\n\n\nfirehose-to-syslog\n\n\n\n\nIncludes implementation code that adds additional metadata (potentially needed for acl)\n\n\nApplication name\n\n\nSpace guid \n name\n\n\nOrg guid \n name\n\n\n\n\n\n\nlogsearch-for-cloudfoundry\n packages this nozzle as a BOSH release\n\n\n\n\ndatadog-firehose-nozzle\n\n\n\n\nA simpler implementation than other real examples\n\n\n\n\nOther References\n\n\n\n\nCF Summit Video \nMonitoring Cloud Foundry: Learning about the Firehose\n\n\nLoggregator github repo\n\n\nOverview of the Loggregator System\n\n\nLoggregator's Slack Channel", 
            "title": "Nozzles"
        }, 
        {
            "location": "/nozzles/#how-to-build-a-nozzle", 
            "text": "", 
            "title": "How to Build a Nozzle"
        }, 
        {
            "location": "/nozzles/#overview", 
            "text": "Cloud Foundry's logging system, Loggregator,\nhas a feature called firehose. The firehose includes the combined stream of logs \nand metrics from every apps as well as\nthe Cloud Foundry platform itself. Building a nozzle could be a solution for   Draining metrics to an external dashboard product for sytem operators  Sending every http request's details into a search tool  Draining all application logs to an external system   Thinking a little differently,  this video shows auto-scaling an app based on firehose metrics   Firehose-to-syslog is a real world, production example \nof a nozzle.", 
            "title": "Overview"
        }, 
        {
            "location": "/nozzles/#building", 
            "text": "Developing a nozzle should be done in Go, as this allows leveraging the NOAA library .\nNOAA does the heavy lifting of establishing\nan authenticated websocket connection to the logging system\nas well as de-serializing the protocol buffers.  Draining the logs consists of:   Authenticating  Establishing a connection to the logging system  Forwarding events on to their ultimate destination   Authenticate by fetching a token from  uaa \nwith a client having the  doppler.firehose  scope:      uaaClient, err := uaago.NewClient(uaaUrl)\n    if err != nil {\n        panic(err)\n    }\n\n    token, err := uaaClient.GetAuthToken(username, password, skipSSL)\n    if err != nil {\n        panic(err)\n    }  Using the token, create a consumer and connect to the Firehose with a subscription id.\nThe id is important, since the firehose looks for connections having the same id and only\nsends an event to one of those connections. This is how a nozzle developer can prevent\nmessage loss during upgrades an other deployments: run at least two instances.      consumer := consumer.New(config.TrafficControllerURL,  tls.Config{\n        InsecureSkipVerify: config.SkipSSL,\n    }, nil)\n    events, errors := consumer.Firehose(firehoseSubscriptionID, token)  Firehose  will give back two channels: one for events and a second for errors.  The events channel receives six different types of events.   ValueMetric: some platform metric at a point in time, emitted by platform components (for example, how many 2xx responses the router has sent out)  CounterEvent: an incrementing counter, emitted by platform components (for example, a diego cells remaining memory capacity)  Error: an error  HttpStartStop: http request details, including both application and platform requests  LogMessage:  a log message for an individual app  ContainerMetric: application container information (for example, memory used)   For the full details on events, check the dropsonde protocol .  The above events show how this data targets two different personae:\nplatform operators and application developers. Keep this in mind when designing an integration.  Having  doppler.firehose  scope gets a nozzle data for  every  application as well as the platform. \nAny filtering based on the event payload is the nozzle implementor's responsibility.\nAn advanced integration could do something like combine a service broker  with a nozzle to:   Let application developers opt-in to logging (implementing filtering in the nozzle)  Establish  SSO  exchange for authentication such that developers only can access logs for their space's apps   For a full working example, see  firehose-nozzle .", 
            "title": "Building"
        }, 
        {
            "location": "/nozzles/#deployment", 
            "text": "Once you've build a nozzle, there are a couple options for deployment", 
            "title": "Deployment"
        }, 
        {
            "location": "/nozzles/#as-a-managed-service", 
            "text": "Visit  managed service \nfor more details on what it means to be a managed service.  See also this example nozzle BOSH release .", 
            "title": "As a Managed Service"
        }, 
        {
            "location": "/nozzles/#as-an-app", 
            "text": "You could also deploy the nozzle on the elastic runtime itself.\nVisit the Tile Generator's section on pushed appliactions \nfor more details.", 
            "title": "As an App"
        }, 
        {
            "location": "/nozzles/#open-source-nozzles", 
            "text": "There are several open source examples you could use\nas a reference for building your nozzle  firehose-nozzle   Example that simply writes to standard out  Useful starting point: scaffolding, tests, etc are in place   example-nozzle   A single file implementation with no tests: as minimal as things can get   gcp-tools-release   In addition to Nozzle data, it drains component syslogs and health data  Shows how to do a bosh-addon (for additional data outside a nozzle)  Nozzle is managed via bosh  Raw logs and metrics data take different paths in the source   firehose-to-syslog   Includes implementation code that adds additional metadata (potentially needed for acl)  Application name  Space guid   name  Org guid   name    logsearch-for-cloudfoundry  packages this nozzle as a BOSH release   datadog-firehose-nozzle   A simpler implementation than other real examples", 
            "title": "Open Source Nozzles"
        }, 
        {
            "location": "/nozzles/#other-references", 
            "text": "CF Summit Video  Monitoring Cloud Foundry: Learning about the Firehose  Loggregator github repo  Overview of the Loggregator System  Loggregator's Slack Channel", 
            "title": "Other References"
        }, 
        {
            "location": "/setup-pcfdev/", 
            "text": "PCF Developer Environment\n\n\nPivotal provides a light-weight (vagrant packaged) instance of PCF with some\nbasic services as a free product named PCF Dev. This is a great environment\nto develop and test everything that runs in the Cloud Foundry Elastic Runtime.\n\n\nIf your integration includes managed services, you will also need an instance\nof bosh that can manage virtual machines and bosh releases for you.\n\nbosh-lite\n works well for that\npurpose.\n\n\nBetween these two components, you will have everything you need to develop\ntiles, except for Pivotal's Ops Manager. But if you followed the recommended\n\nstaged development approach\n you will not need an actual full\nPCF environment until the later phases of your development.\n\n\nSetting up PCF Dev\n\n\n\n\nTry PCF on your Local Workstation\n\n\n\n\nSetting up bosh-lite\n\n\n\n\nInstall bosh-lite\n\n\n\n\n\n\nNote:\n\n\nFor this type of development environment, you only need bosh-lite\nitself to deploy managed service releases. You do \nnot\n need to follow the\ninstructions to Deploy Cloud Foundry in bosh-lite, as Cloud Foundry is\nprovided by the PCF Dev installation above.", 
            "title": "Developer Environment"
        }, 
        {
            "location": "/setup-pcfdev/#pcf-developer-environment", 
            "text": "Pivotal provides a light-weight (vagrant packaged) instance of PCF with some\nbasic services as a free product named PCF Dev. This is a great environment\nto develop and test everything that runs in the Cloud Foundry Elastic Runtime.  If your integration includes managed services, you will also need an instance\nof bosh that can manage virtual machines and bosh releases for you. bosh-lite  works well for that\npurpose.  Between these two components, you will have everything you need to develop\ntiles, except for Pivotal's Ops Manager. But if you followed the recommended staged development approach  you will not need an actual full\nPCF environment until the later phases of your development.", 
            "title": "PCF Developer Environment"
        }, 
        {
            "location": "/setup-pcfdev/#setting-up-pcf-dev", 
            "text": "Try PCF on your Local Workstation", 
            "title": "Setting up PCF Dev"
        }, 
        {
            "location": "/setup-pcfdev/#setting-up-bosh-lite", 
            "text": "Install bosh-lite    Note:  For this type of development environment, you only need bosh-lite\nitself to deploy managed service releases. You do  not  need to follow the\ninstructions to Deploy Cloud Foundry in bosh-lite, as Cloud Foundry is\nprovided by the PCF Dev installation above.", 
            "title": "Setting up bosh-lite"
        }, 
        {
            "location": "/setup-pcf/", 
            "text": "Setting up PCF\n\n\nPartners who participate in our program have access to a number of shared\nPCF environments that are operated and managed by Pivotal. If you are not\n(yet) in our program, need a dedicated environment, or want to be able to\nwork offline, you can set up your own environment. Often, a\n\ndeveloper environment\n is sufficient for the early\nphases of an integration effort. But eventually, you will need access to\na complete environment that includes Pivotal's Ops Manager on one of the\nsupported infrastructures:\n\n\n\n\nInstalling Pivotal Cloud Foundry\n\n\n \n\n\nOperating Pivotal Cloud Foundry\n\n\n \n\n\nUpgrading Pivotal Cloud Foundry", 
            "title": "Full PCF Environment"
        }, 
        {
            "location": "/setup-pcf/#setting-up-pcf", 
            "text": "Partners who participate in our program have access to a number of shared\nPCF environments that are operated and managed by Pivotal. If you are not\n(yet) in our program, need a dedicated environment, or want to be able to\nwork offline, you can set up your own environment. Often, a developer environment  is sufficient for the early\nphases of an integration effort. But eventually, you will need access to\na complete environment that includes Pivotal's Ops Manager on one of the\nsupported infrastructures:   Installing Pivotal Cloud Foundry     Operating Pivotal Cloud Foundry     Upgrading Pivotal Cloud Foundry", 
            "title": "Setting up PCF"
        }, 
        {
            "location": "/troubleshooting/", 
            "text": "Troubleshooting\n\n\nSooner or later you will run into problems that require digging a little bit deeper.\nHere are some great resources on how to best troubleshoot more complex issues:\n\n\n\n\nTroubleshooting PCF\n\n\nTroubleshooting Applications\n\n\nAdvanced Troubleshooting with BOSH", 
            "title": "Troubleshooting"
        }, 
        {
            "location": "/troubleshooting/#troubleshooting", 
            "text": "Sooner or later you will run into problems that require digging a little bit deeper.\nHere are some great resources on how to best troubleshoot more complex issues:   Troubleshooting PCF  Troubleshooting Applications  Advanced Troubleshooting with BOSH", 
            "title": "Troubleshooting"
        }, 
        {
            "location": "/contacts/", 
            "text": "Contact Us\n\n\nTo learn more about the Pivotal IVS Partner Program, or to request\nour assistance with your integration project, please contact us at\none of the following addresses:\n\n\n\n\nProgram Manager: \nMarina Joseph\n\n\nBusiness Development: \nNima Badiey\n\n\nPlatform Engineering: \nGuido Westenberg\n\n\n\n\nContributions\n\n\nThe source code for this site is in a public\n\nGithub repository\n.\n\n\nWe greatly appreciate contributions to the content in the form of pull\nrequests, as well as Github issues with corrections, comments, or\nsuggestions.\n\n\nThe Github Pages site is created from the Markdown source files using\n\nmkdocs\n. To preview your changes, run the\ncommand \nmkdocs serve\n in the root directory of your local git clone\nof this repository.", 
            "title": "Contacts"
        }, 
        {
            "location": "/contacts/#contact-us", 
            "text": "To learn more about the Pivotal IVS Partner Program, or to request\nour assistance with your integration project, please contact us at\none of the following addresses:   Program Manager:  Marina Joseph  Business Development:  Nima Badiey  Platform Engineering:  Guido Westenberg", 
            "title": "Contact Us"
        }, 
        {
            "location": "/contacts/#contributions", 
            "text": "The source code for this site is in a public Github repository .  We greatly appreciate contributions to the content in the form of pull\nrequests, as well as Github issues with corrections, comments, or\nsuggestions.  The Github Pages site is created from the Markdown source files using mkdocs . To preview your changes, run the\ncommand  mkdocs serve  in the root directory of your local git clone\nof this repository.", 
            "title": "Contributions"
        }
    ]
}